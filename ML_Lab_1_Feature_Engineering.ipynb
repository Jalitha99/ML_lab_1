{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4C-hOx4RxVle"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Constants\n",
        "L1 = 'label_1'\n",
        "L2 = 'label_2'\n",
        "L3 = 'label_3'\n",
        "L4 = 'label_4'\n",
        "LABELS = [L1, L2, L3, L4]\n",
        "AGE_LABEL = L2\n",
        "FEATURES =  [f'feature_{i}' for i in range(1,257)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/sample_data/train.csv\")\n",
        "valid_df = pd.read_csv(\"/content/sample_data/valid.csv\")\n",
        "test_df = pd.read_csv(\"/content/sample_data/test.csv\")\n",
        "\n",
        "train_df.head()\n",
        "valid_df.head()\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "etbd2oE0xvGv",
        "outputId": "3ff410a1-2e5b-41f6-8611-7105c1dae3d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "0  -1.141206  -0.279703   1.019681   2.605902   0.460391  -1.167380   \n",
              "1  -1.796767  -0.056758   0.771219   4.414086  -1.229059   1.732098   \n",
              "2  -1.388968  -0.418296   0.186543   2.803852  -1.499095   1.395180   \n",
              "3   1.276844  -0.112323  -0.310796   2.251175   0.283670  -0.581020   \n",
              "4  -1.560815  -0.168494   1.249770   1.869219  -1.646049   0.132156   \n",
              "\n",
              "   feature_7  feature_8  feature_9  feature_10  ...  feature_251  feature_252  \\\n",
              "0  -1.149165  -1.205164   2.468966   -2.729526  ...    -0.868282    -0.429783   \n",
              "1   0.063241  -0.126311   1.322355   -3.461282  ...     0.227806     0.209200   \n",
              "2   0.739648   0.274060   1.228789   -3.081147  ...    -0.692679     0.449235   \n",
              "3  -0.024439  -0.306097   2.424685   -1.714863  ...    -0.690499    -1.077949   \n",
              "4  -0.664602   0.483327   1.728020   -2.258071  ...    -0.510597     1.213396   \n",
              "\n",
              "   feature_253  feature_254  feature_255  feature_256  label_1  label_2  \\\n",
              "0     0.438561    -1.625122     0.599944    -0.615575      NaN      NaN   \n",
              "1     2.200402    -1.701029     1.163999    -1.570136      NaN      NaN   \n",
              "2     1.377531    -1.854203    -0.040538    -2.164104      NaN      NaN   \n",
              "3     0.930102    -2.758352    -0.246738    -1.389013      NaN      NaN   \n",
              "4     2.497490    -1.597984    -0.163483    -1.735939      NaN      NaN   \n",
              "\n",
              "   label_3  label_4  \n",
              "0      NaN      NaN  \n",
              "1      NaN      NaN  \n",
              "2      NaN      NaN  \n",
              "3      NaN      NaN  \n",
              "4      NaN      NaN  \n",
              "\n",
              "[5 rows x 260 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee253236-c33e-4331-916f-d2ba25d9fdff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_251</th>\n",
              "      <th>feature_252</th>\n",
              "      <th>feature_253</th>\n",
              "      <th>feature_254</th>\n",
              "      <th>feature_255</th>\n",
              "      <th>feature_256</th>\n",
              "      <th>label_1</th>\n",
              "      <th>label_2</th>\n",
              "      <th>label_3</th>\n",
              "      <th>label_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.141206</td>\n",
              "      <td>-0.279703</td>\n",
              "      <td>1.019681</td>\n",
              "      <td>2.605902</td>\n",
              "      <td>0.460391</td>\n",
              "      <td>-1.167380</td>\n",
              "      <td>-1.149165</td>\n",
              "      <td>-1.205164</td>\n",
              "      <td>2.468966</td>\n",
              "      <td>-2.729526</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.868282</td>\n",
              "      <td>-0.429783</td>\n",
              "      <td>0.438561</td>\n",
              "      <td>-1.625122</td>\n",
              "      <td>0.599944</td>\n",
              "      <td>-0.615575</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.796767</td>\n",
              "      <td>-0.056758</td>\n",
              "      <td>0.771219</td>\n",
              "      <td>4.414086</td>\n",
              "      <td>-1.229059</td>\n",
              "      <td>1.732098</td>\n",
              "      <td>0.063241</td>\n",
              "      <td>-0.126311</td>\n",
              "      <td>1.322355</td>\n",
              "      <td>-3.461282</td>\n",
              "      <td>...</td>\n",
              "      <td>0.227806</td>\n",
              "      <td>0.209200</td>\n",
              "      <td>2.200402</td>\n",
              "      <td>-1.701029</td>\n",
              "      <td>1.163999</td>\n",
              "      <td>-1.570136</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.388968</td>\n",
              "      <td>-0.418296</td>\n",
              "      <td>0.186543</td>\n",
              "      <td>2.803852</td>\n",
              "      <td>-1.499095</td>\n",
              "      <td>1.395180</td>\n",
              "      <td>0.739648</td>\n",
              "      <td>0.274060</td>\n",
              "      <td>1.228789</td>\n",
              "      <td>-3.081147</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.692679</td>\n",
              "      <td>0.449235</td>\n",
              "      <td>1.377531</td>\n",
              "      <td>-1.854203</td>\n",
              "      <td>-0.040538</td>\n",
              "      <td>-2.164104</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.276844</td>\n",
              "      <td>-0.112323</td>\n",
              "      <td>-0.310796</td>\n",
              "      <td>2.251175</td>\n",
              "      <td>0.283670</td>\n",
              "      <td>-0.581020</td>\n",
              "      <td>-0.024439</td>\n",
              "      <td>-0.306097</td>\n",
              "      <td>2.424685</td>\n",
              "      <td>-1.714863</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.690499</td>\n",
              "      <td>-1.077949</td>\n",
              "      <td>0.930102</td>\n",
              "      <td>-2.758352</td>\n",
              "      <td>-0.246738</td>\n",
              "      <td>-1.389013</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.560815</td>\n",
              "      <td>-0.168494</td>\n",
              "      <td>1.249770</td>\n",
              "      <td>1.869219</td>\n",
              "      <td>-1.646049</td>\n",
              "      <td>0.132156</td>\n",
              "      <td>-0.664602</td>\n",
              "      <td>0.483327</td>\n",
              "      <td>1.728020</td>\n",
              "      <td>-2.258071</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.510597</td>\n",
              "      <td>1.213396</td>\n",
              "      <td>2.497490</td>\n",
              "      <td>-1.597984</td>\n",
              "      <td>-0.163483</td>\n",
              "      <td>-1.735939</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 260 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee253236-c33e-4331-916f-d2ba25d9fdff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee253236-c33e-4331-916f-d2ba25d9fdff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee253236-c33e-4331-916f-d2ba25d9fdff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f59099ec-fd62-46f7-a1ee-30e816033eba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f59099ec-fd62-46f7-a1ee-30e816033eba')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f59099ec-fd62-46f7-a1ee-30e816033eba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()\n",
        "train_df[L1].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKYHHZQ1yOZs",
        "outputId": "4fb8c186-594e-4d31-ec91-27640d9ab4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 28520 entries, 0 to 28519\n",
            "Columns: 260 entries, feature_1 to label_4\n",
            "dtypes: float64(257), int64(3)\n",
            "memory usage: 56.6 MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12    485\n",
              "35    484\n",
              "26    483\n",
              "60    482\n",
              "24    482\n",
              "25    481\n",
              "59    481\n",
              "10    481\n",
              "54    481\n",
              "45    480\n",
              "41    480\n",
              "9     480\n",
              "2     479\n",
              "42    479\n",
              "47    479\n",
              "6     479\n",
              "56    479\n",
              "34    478\n",
              "52    478\n",
              "3     478\n",
              "14    478\n",
              "33    478\n",
              "43    477\n",
              "1     477\n",
              "13    477\n",
              "20    477\n",
              "23    477\n",
              "30    476\n",
              "51    476\n",
              "32    476\n",
              "53    476\n",
              "22    476\n",
              "38    476\n",
              "49    476\n",
              "55    475\n",
              "28    474\n",
              "8     474\n",
              "40    474\n",
              "48    474\n",
              "21    474\n",
              "4     474\n",
              "39    473\n",
              "17    473\n",
              "7     473\n",
              "15    472\n",
              "58    472\n",
              "5     471\n",
              "27    471\n",
              "31    470\n",
              "19    469\n",
              "11    469\n",
              "46    469\n",
              "29    469\n",
              "36    468\n",
              "16    468\n",
              "50    467\n",
              "37    467\n",
              "44    467\n",
              "57    466\n",
              "18    465\n",
              "Name: label_1, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.arrays.period import validate_dtype_freq\n",
        "# Scaling the data\n",
        "from sklearn.preprocessing import RobustScaler # RobustScaler\n",
        "\n",
        "x_train = {}\n",
        "x_valid = {}\n",
        "x_test = {}\n",
        "y_train = {}\n",
        "y_valid = {}\n",
        "\n",
        "for target_label in LABELS:\n",
        "  tr_df = train_df[train_df['label_2'].notna()] if target_label == 'label_2' else train_df # remove NA values in label 2\n",
        "  vl_df = valid_df[valid_df['label_2'].notna()] if target_label == 'label_2' else valid_df\n",
        "  t_df = test_df\n",
        "  scaler = RobustScaler()\n",
        "  x_train[target_label] = pd.DataFrame(scaler.fit_transform(tr_df.drop(LABELS, axis=1)), columns = FEATURES)\n",
        "  x_test[target_label] = pd.DataFrame(scaler.fit_transform(t_df.drop(LABELS, axis=1)), columns = FEATURES)\n",
        "  y_train[target_label] = tr_df[target_label]\n",
        "  x_valid[target_label] = pd.DataFrame(scaler.transform(vl_df.drop(LABELS, axis=1)), columns = FEATURES)\n",
        "  y_valid[target_label] = vl_df[target_label]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHrAR-CizVr_",
        "outputId": "bd1cfcce-a64f-4dd1-9e1e-158c63e02f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(750, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For Label 1**"
      ],
      "metadata": {
        "id": "KuGHJ8Oq4S_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without Feature Engineering"
      ],
      "metadata": {
        "id": "6bE36JNa4bFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[L1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "0oNeXWpo4lZ4",
        "outputId": "f89e1d7a-b486-47df-e657-d7af55348597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "0      -1.309586   0.235701   0.943739   1.110687   0.493583  -0.232368   \n",
              "1      -1.144159  -0.295674   0.837377   2.514509  -0.718433   1.537233   \n",
              "2      -1.292525   0.186803  -0.330437   2.726045  -0.915203   1.013608   \n",
              "3       0.669594  -1.191524  -0.251777   0.560848   0.193810   0.728978   \n",
              "4      -1.345805   0.084043   0.418116   2.155265  -0.227710   1.064978   \n",
              "...          ...        ...        ...        ...        ...        ...   \n",
              "28515   0.043336   1.192542  -0.149975   0.011312   2.636595  -0.068369   \n",
              "28516   1.215430  -0.535137   0.051517  -0.021644   0.280856  -0.269055   \n",
              "28517   0.997528  -0.016963   0.116092   0.297648   1.067387   0.208798   \n",
              "28518  -0.605893  -0.008649   0.009349  -0.613440   0.888404  -0.589037   \n",
              "28519   0.763188  -0.207126   0.459697  -0.435380   0.961052  -0.455518   \n",
              "\n",
              "       feature_7  feature_8  feature_9  feature_10  ...  feature_247  \\\n",
              "0      -0.624554  -0.504571   0.132999    0.095217  ...     1.583006   \n",
              "1       0.286751  -0.431414   1.105227   -0.783768  ...     1.036040   \n",
              "2       1.247330  -1.564947   0.951931   -1.012765  ...     0.297848   \n",
              "3       0.931314   0.170499   1.527067    0.288711  ...     0.829376   \n",
              "4      -0.248008   0.090402   0.538791   -1.573073  ...     1.058010   \n",
              "...          ...        ...        ...         ...  ...          ...   \n",
              "28515  -0.978061   0.177880   1.175240    0.563477  ...     0.670030   \n",
              "28516   0.761116  -1.611506  -0.137716    0.093801  ...     0.680854   \n",
              "28517   0.236824  -0.038200   0.211088    0.628452  ...     0.334185   \n",
              "28518   0.129601  -0.855883   0.201302   -0.727748  ...     0.465296   \n",
              "28519   0.601866   0.921103  -1.020922    1.548995  ...     0.079121   \n",
              "\n",
              "       feature_248  feature_249  feature_250  feature_251  feature_252  \\\n",
              "0         1.101137    -0.786061     0.622750    -0.503841    -0.862208   \n",
              "1        -0.688550    -1.640606    -0.053767    -0.486404    -0.493145   \n",
              "2         0.303437    -2.323521    -0.182392    -0.006368     0.086269   \n",
              "3        -0.102070    -2.596694    -0.616500     0.544197     0.307588   \n",
              "4        -0.117040    -1.419770     0.362046    -0.435119    -0.786176   \n",
              "...            ...          ...          ...          ...          ...   \n",
              "28515    -0.158732    -0.525769     1.257927     0.567362    -0.776576   \n",
              "28516    -0.432984    -0.031154     0.887144    -0.127631     0.039676   \n",
              "28517    -0.180739    -0.387017    -0.955283     0.850339    -1.401814   \n",
              "28518     0.307306     0.663333     0.233262     0.540602    -0.434947   \n",
              "28519    -0.087894    -1.330237    -0.403272     0.973497    -0.812996   \n",
              "\n",
              "       feature_253  feature_254  feature_255  feature_256  \n",
              "0        -1.063657    -0.033389    -0.726253     0.785181  \n",
              "1        -1.293456    -0.320623     0.746471    -0.660619  \n",
              "2         0.762691     0.577715    -0.946525    -0.585987  \n",
              "3        -0.577020     0.401594    -1.154003     0.207497  \n",
              "4         0.068403    -0.787532     1.939043     0.183946  \n",
              "...            ...          ...          ...          ...  \n",
              "28515    -0.718924     0.924023     0.570760     0.442692  \n",
              "28516    -0.151647    -0.303670     0.903381    -0.282937  \n",
              "28517     0.774752     1.397541    -0.214777    -0.206945  \n",
              "28518     0.085522    -0.173189    -1.037877    -0.075089  \n",
              "28519     1.066722     1.259609    -0.024581    -1.249044  \n",
              "\n",
              "[28520 rows x 256 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f521acc-463a-4d44-b3cd-3fb69cf698dc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_247</th>\n",
              "      <th>feature_248</th>\n",
              "      <th>feature_249</th>\n",
              "      <th>feature_250</th>\n",
              "      <th>feature_251</th>\n",
              "      <th>feature_252</th>\n",
              "      <th>feature_253</th>\n",
              "      <th>feature_254</th>\n",
              "      <th>feature_255</th>\n",
              "      <th>feature_256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.309586</td>\n",
              "      <td>0.235701</td>\n",
              "      <td>0.943739</td>\n",
              "      <td>1.110687</td>\n",
              "      <td>0.493583</td>\n",
              "      <td>-0.232368</td>\n",
              "      <td>-0.624554</td>\n",
              "      <td>-0.504571</td>\n",
              "      <td>0.132999</td>\n",
              "      <td>0.095217</td>\n",
              "      <td>...</td>\n",
              "      <td>1.583006</td>\n",
              "      <td>1.101137</td>\n",
              "      <td>-0.786061</td>\n",
              "      <td>0.622750</td>\n",
              "      <td>-0.503841</td>\n",
              "      <td>-0.862208</td>\n",
              "      <td>-1.063657</td>\n",
              "      <td>-0.033389</td>\n",
              "      <td>-0.726253</td>\n",
              "      <td>0.785181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.144159</td>\n",
              "      <td>-0.295674</td>\n",
              "      <td>0.837377</td>\n",
              "      <td>2.514509</td>\n",
              "      <td>-0.718433</td>\n",
              "      <td>1.537233</td>\n",
              "      <td>0.286751</td>\n",
              "      <td>-0.431414</td>\n",
              "      <td>1.105227</td>\n",
              "      <td>-0.783768</td>\n",
              "      <td>...</td>\n",
              "      <td>1.036040</td>\n",
              "      <td>-0.688550</td>\n",
              "      <td>-1.640606</td>\n",
              "      <td>-0.053767</td>\n",
              "      <td>-0.486404</td>\n",
              "      <td>-0.493145</td>\n",
              "      <td>-1.293456</td>\n",
              "      <td>-0.320623</td>\n",
              "      <td>0.746471</td>\n",
              "      <td>-0.660619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.292525</td>\n",
              "      <td>0.186803</td>\n",
              "      <td>-0.330437</td>\n",
              "      <td>2.726045</td>\n",
              "      <td>-0.915203</td>\n",
              "      <td>1.013608</td>\n",
              "      <td>1.247330</td>\n",
              "      <td>-1.564947</td>\n",
              "      <td>0.951931</td>\n",
              "      <td>-1.012765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.297848</td>\n",
              "      <td>0.303437</td>\n",
              "      <td>-2.323521</td>\n",
              "      <td>-0.182392</td>\n",
              "      <td>-0.006368</td>\n",
              "      <td>0.086269</td>\n",
              "      <td>0.762691</td>\n",
              "      <td>0.577715</td>\n",
              "      <td>-0.946525</td>\n",
              "      <td>-0.585987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.669594</td>\n",
              "      <td>-1.191524</td>\n",
              "      <td>-0.251777</td>\n",
              "      <td>0.560848</td>\n",
              "      <td>0.193810</td>\n",
              "      <td>0.728978</td>\n",
              "      <td>0.931314</td>\n",
              "      <td>0.170499</td>\n",
              "      <td>1.527067</td>\n",
              "      <td>0.288711</td>\n",
              "      <td>...</td>\n",
              "      <td>0.829376</td>\n",
              "      <td>-0.102070</td>\n",
              "      <td>-2.596694</td>\n",
              "      <td>-0.616500</td>\n",
              "      <td>0.544197</td>\n",
              "      <td>0.307588</td>\n",
              "      <td>-0.577020</td>\n",
              "      <td>0.401594</td>\n",
              "      <td>-1.154003</td>\n",
              "      <td>0.207497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.345805</td>\n",
              "      <td>0.084043</td>\n",
              "      <td>0.418116</td>\n",
              "      <td>2.155265</td>\n",
              "      <td>-0.227710</td>\n",
              "      <td>1.064978</td>\n",
              "      <td>-0.248008</td>\n",
              "      <td>0.090402</td>\n",
              "      <td>0.538791</td>\n",
              "      <td>-1.573073</td>\n",
              "      <td>...</td>\n",
              "      <td>1.058010</td>\n",
              "      <td>-0.117040</td>\n",
              "      <td>-1.419770</td>\n",
              "      <td>0.362046</td>\n",
              "      <td>-0.435119</td>\n",
              "      <td>-0.786176</td>\n",
              "      <td>0.068403</td>\n",
              "      <td>-0.787532</td>\n",
              "      <td>1.939043</td>\n",
              "      <td>0.183946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28515</th>\n",
              "      <td>0.043336</td>\n",
              "      <td>1.192542</td>\n",
              "      <td>-0.149975</td>\n",
              "      <td>0.011312</td>\n",
              "      <td>2.636595</td>\n",
              "      <td>-0.068369</td>\n",
              "      <td>-0.978061</td>\n",
              "      <td>0.177880</td>\n",
              "      <td>1.175240</td>\n",
              "      <td>0.563477</td>\n",
              "      <td>...</td>\n",
              "      <td>0.670030</td>\n",
              "      <td>-0.158732</td>\n",
              "      <td>-0.525769</td>\n",
              "      <td>1.257927</td>\n",
              "      <td>0.567362</td>\n",
              "      <td>-0.776576</td>\n",
              "      <td>-0.718924</td>\n",
              "      <td>0.924023</td>\n",
              "      <td>0.570760</td>\n",
              "      <td>0.442692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28516</th>\n",
              "      <td>1.215430</td>\n",
              "      <td>-0.535137</td>\n",
              "      <td>0.051517</td>\n",
              "      <td>-0.021644</td>\n",
              "      <td>0.280856</td>\n",
              "      <td>-0.269055</td>\n",
              "      <td>0.761116</td>\n",
              "      <td>-1.611506</td>\n",
              "      <td>-0.137716</td>\n",
              "      <td>0.093801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.680854</td>\n",
              "      <td>-0.432984</td>\n",
              "      <td>-0.031154</td>\n",
              "      <td>0.887144</td>\n",
              "      <td>-0.127631</td>\n",
              "      <td>0.039676</td>\n",
              "      <td>-0.151647</td>\n",
              "      <td>-0.303670</td>\n",
              "      <td>0.903381</td>\n",
              "      <td>-0.282937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28517</th>\n",
              "      <td>0.997528</td>\n",
              "      <td>-0.016963</td>\n",
              "      <td>0.116092</td>\n",
              "      <td>0.297648</td>\n",
              "      <td>1.067387</td>\n",
              "      <td>0.208798</td>\n",
              "      <td>0.236824</td>\n",
              "      <td>-0.038200</td>\n",
              "      <td>0.211088</td>\n",
              "      <td>0.628452</td>\n",
              "      <td>...</td>\n",
              "      <td>0.334185</td>\n",
              "      <td>-0.180739</td>\n",
              "      <td>-0.387017</td>\n",
              "      <td>-0.955283</td>\n",
              "      <td>0.850339</td>\n",
              "      <td>-1.401814</td>\n",
              "      <td>0.774752</td>\n",
              "      <td>1.397541</td>\n",
              "      <td>-0.214777</td>\n",
              "      <td>-0.206945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28518</th>\n",
              "      <td>-0.605893</td>\n",
              "      <td>-0.008649</td>\n",
              "      <td>0.009349</td>\n",
              "      <td>-0.613440</td>\n",
              "      <td>0.888404</td>\n",
              "      <td>-0.589037</td>\n",
              "      <td>0.129601</td>\n",
              "      <td>-0.855883</td>\n",
              "      <td>0.201302</td>\n",
              "      <td>-0.727748</td>\n",
              "      <td>...</td>\n",
              "      <td>0.465296</td>\n",
              "      <td>0.307306</td>\n",
              "      <td>0.663333</td>\n",
              "      <td>0.233262</td>\n",
              "      <td>0.540602</td>\n",
              "      <td>-0.434947</td>\n",
              "      <td>0.085522</td>\n",
              "      <td>-0.173189</td>\n",
              "      <td>-1.037877</td>\n",
              "      <td>-0.075089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28519</th>\n",
              "      <td>0.763188</td>\n",
              "      <td>-0.207126</td>\n",
              "      <td>0.459697</td>\n",
              "      <td>-0.435380</td>\n",
              "      <td>0.961052</td>\n",
              "      <td>-0.455518</td>\n",
              "      <td>0.601866</td>\n",
              "      <td>0.921103</td>\n",
              "      <td>-1.020922</td>\n",
              "      <td>1.548995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.079121</td>\n",
              "      <td>-0.087894</td>\n",
              "      <td>-1.330237</td>\n",
              "      <td>-0.403272</td>\n",
              "      <td>0.973497</td>\n",
              "      <td>-0.812996</td>\n",
              "      <td>1.066722</td>\n",
              "      <td>1.259609</td>\n",
              "      <td>-0.024581</td>\n",
              "      <td>-1.249044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28520 rows × 256 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f521acc-463a-4d44-b3cd-3fb69cf698dc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f521acc-463a-4d44-b3cd-3fb69cf698dc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f521acc-463a-4d44-b3cd-3fb69cf698dc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a166467d-ad5a-4e83-8fd6-95d46078fb42\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a166467d-ad5a-4e83-8fd6-95d46078fb42')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a166467d-ad5a-4e83-8fd6-95d46078fb42 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model to predict label_1\n",
        "from sklearn import svm\n",
        "\n",
        "clf = svm.SVC(kernel='linear')\n",
        "\n",
        "clf.fit(x_train[L1], y_train[L1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "-eD_T2LP52kX",
        "outputId": "e58ffd9f-901a-4e56-b7e3-88d1af3ef793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "y_pred = clf.predict(x_valid[L1]) # Predicting the validation data set"
      ],
      "metadata": {
        "id": "wNdsEQaF6z2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy of the validation data set\n",
        "print(metrics.confusion_matrix(y_valid[L1], y_pred))\n",
        "print(metrics.accuracy_score(y_valid[L1], y_pred))\n",
        "print(metrics.precision_score(y_valid[L1], y_pred, average='weighted'))\n",
        "print(metrics.recall_score(y_valid[L1], y_pred, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqzLP-T08XCA",
        "outputId": "e32a6c76-67d9-4f8c-dc43-c7aec9c954d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13  0  0 ...  0  0  0]\n",
            " [ 0  9  0 ...  0  0  0]\n",
            " [ 0  0 12 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ... 20  0  0]\n",
            " [ 0  0  0 ...  0 10  0]\n",
            " [ 0  0  0 ...  0  0 10]]\n",
            "0.9906666666666667\n",
            "0.9915571095571095\n",
            "0.9906666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting the label_1 of the test data set\n",
        "y_pred_test = clf.predict(x_test[L1])"
      ],
      "metadata": {
        "id": "TFmRnpb-9tgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoNhxfgE-uwX",
        "outputId": "96fca98d-830c-4418-bf78-016a8f6bbe37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([45, 45, 45, 45, 45, 45,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
              "        5, 60, 60, 60, 60, 60, 60, 60, 60, 19, 19, 19, 19, 19, 19, 19, 19,\n",
              "       19, 19, 39, 19, 19, 19, 19, 19, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
              "       11, 11, 11, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 25, 25, 25,\n",
              "       25, 25, 25, 24, 25, 25, 25, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
              "       46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 51, 51, 51, 51, 51, 51, 51,\n",
              "       51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 35, 35, 35, 35, 35, 35, 35,\n",
              "       35, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 53, 53, 53, 53, 53,\n",
              "       53, 22, 53, 53, 53,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 40, 40,\n",
              "       40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 43, 43, 43, 43,\n",
              "       43, 43, 43, 43, 43, 43, 43, 58, 58, 58, 58, 58, 58, 58, 58, 44, 44,\n",
              "       44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 37, 37, 37, 37, 37,\n",
              "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 55, 55, 55, 55, 55,\n",
              "       55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 17, 17, 17, 17, 17,\n",
              "       17, 17, 17, 17, 17, 17, 17, 17,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
              "        2,  2,  2, 47, 47, 47, 47, 47, 47, 47, 47, 47, 58, 47, 47, 47, 54,\n",
              "       54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 21, 21, 21, 21, 21, 21, 21,\n",
              "       21, 21, 21, 21, 21, 34, 34, 34, 34, 34, 34, 34, 34, 34, 23, 23, 23,\n",
              "       23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 10, 10, 10, 10, 10, 10, 10,\n",
              "       10, 10, 10, 10, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
              "       28, 28, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,  7,  7,  7,\n",
              "        7,  7,  7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4, 48, 48, 48, 48, 48,\n",
              "       48, 48, 48, 48, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
              "       32, 32, 32, 12, 12, 12, 12, 12, 12, 12, 12, 22, 22, 22, 22, 22, 22,\n",
              "       22, 22, 22, 22, 22, 22, 22, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38,\n",
              "       38, 38, 38, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
              "       36, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 50, 50, 50, 50, 50,\n",
              "       50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 14,\n",
              "       14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "       15, 24, 24, 24, 24, 24, 24, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
              "       13, 13, 29, 29, 29, 29, 29, 29, 25, 29, 29, 29, 51, 29, 29, 29, 29,\n",
              "       29, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  9,  9,  9,  9,  9,  9,  9,\n",
              "        9,  9, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 27, 27, 27, 27,\n",
              "       27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 42, 42, 42, 42, 42, 42, 42,\n",
              "       42, 42, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 41, 41, 41, 41, 41,\n",
              "       41, 41, 41, 41, 41, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57,\n",
              "       57, 57, 57, 57, 57,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
              "        8,  8, 35, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
              "       33, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31,\n",
              "       31, 31, 31, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
              "       16, 16, 16, 16, 16, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
              "       30, 30, 30, 30, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
              "       39, 39])"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With Feature Engineering"
      ],
      "metadata": {
        "id": "Gce7rbqs_REX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# With  selectKBest method\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "selector =  SelectKBest(f_classif, k=150) #  with only using 150 features\n",
        "x_new_train = selector.fit_transform(x_train[L1], y_train[L1])\n",
        "x_new_valid = selector.transform(x_valid[L1])\n",
        "x_new_test = selector.transform(x_test[L1])\n",
        "print('shape training', x_new_train.shape)\n",
        "print('shape validation', x_new_valid.shape)\n",
        "print('shape test', x_new_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQC-q2Nb_T1u",
        "outputId": "c522ecd8-4c39-45fb-f96e-7b5a6afb954e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape training (28520, 150)\n",
            "shape validation (750, 150)\n",
            "shape test (750, 150)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(kernel='linear')\n",
        "\n",
        "clf.fit(x_new_train, y_train[L1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "y3LNFoLd_-kG",
        "outputId": "df455658-8c71-42b7-8476-ab52aecca82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(selector.transform(x_valid[L1]))\n",
        "print(metrics.confusion_matrix(y_valid[L1], y_pred))\n",
        "print(metrics.accuracy_score(y_valid[L1], y_pred))\n",
        "print(metrics.precision_score(y_valid[L1], y_pred, average='weighted'))\n",
        "print(metrics.recall_score(y_valid[L1], y_pred, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaOA8aHfAZBX",
        "outputId": "01f3235a-5503-420c-fc46-7ea3c3da8c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13  0  0 ...  0  0  0]\n",
            " [ 0  9  0 ...  0  0  0]\n",
            " [ 0  0 12 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ... 19  0  1]\n",
            " [ 0  0  0 ...  0 10  0]\n",
            " [ 0  0  0 ...  1  0  9]]\n",
            "0.9826666666666667\n",
            "0.9839200725200726\n",
            "0.9826666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding PCA to the selectKBest results\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=0.95, svd_solver='full')\n",
        "pca.fit(x_new_train)\n",
        "x_train_trf = pd.DataFrame(pca.transform(x_new_train)) # transforming data to fit into pca\n",
        "x_valid_trf = pd.DataFrame(pca.transform(x_new_valid))\n",
        "x_test_trf = pd.DataFrame(pca.transform(x_new_test))\n",
        "print('Shape after PCA x_train : ', x_train_trf.shape)\n",
        "print('Shape after PCA x_valid : ', x_valid_trf.shape)\n",
        "print('Shape after PCA x_test : ', x_valid_trf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyADbW9sBt93",
        "outputId": "40342212-a621-4c8e-8e42-fbb00c0bd498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after PCA x_train :  (28520, 57)\n",
            "Shape after PCA x_valid :  (750, 57)\n",
            "Shape after PCA x_test :  (750, 57)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(kernel='linear')\n",
        "\n",
        "clf.fit(x_train_trf, y_train[L1])\n",
        "\n",
        "y_pred = clf.predict(x_valid_trf)\n",
        "print(metrics.confusion_matrix(y_valid[L1], y_pred))\n",
        "print(metrics.accuracy_score(y_valid[L1], y_pred))\n",
        "print(metrics.precision_score(y_valid[L1], y_pred, average='weighted'))\n",
        "print(metrics.recall_score(y_valid[L1], y_pred, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs7qvohrCg4n",
        "outputId": "1bb302e2-c7db-4569-e8a4-5313e2bd0eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11  0  0 ...  0  0  0]\n",
            " [ 0  8  0 ...  0  0  0]\n",
            " [ 0  0 12 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ... 18  0  1]\n",
            " [ 0  0  0 ...  0 10  0]\n",
            " [ 0  0  0 ...  1  0  9]]\n",
            "0.9666666666666667\n",
            "0.9697322862322861\n",
            "0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting the test data\n",
        "y_pred_test_fe = clf.predict(x_test_trf)\n",
        "y_pred_test_fe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ljpKqcBGYmQ",
        "outputId": "a1c9165f-4e42-43ec-adff-a6c575a8e448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([45, 45, 45, 45, 45, 45,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
              "        5, 60, 60, 60, 60, 60, 60, 60, 60, 19, 19, 19, 19, 19, 19, 19, 19,\n",
              "       19, 19, 39, 19, 19, 19, 19, 19, 11, 11, 11, 11, 11, 11, 34, 11, 11,\n",
              "       11, 11, 11, 52, 36, 52, 52, 52, 52, 52, 52, 57, 52, 52, 25, 25, 25,\n",
              "       25, 25, 25, 25, 25, 25, 25, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
              "       46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 51, 51, 51, 51, 51, 51, 51,\n",
              "       51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 35, 35, 35, 35, 35, 35, 35,\n",
              "       35, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 53, 53, 53, 53, 53,\n",
              "       53, 53, 53, 53, 53,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 40, 40,\n",
              "       40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 43, 43, 43, 43,\n",
              "       43, 43, 43, 43, 43, 43, 43, 36, 58, 52, 58, 58, 58, 58, 58, 44, 44,\n",
              "       44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 37, 37, 37, 37, 37,\n",
              "       37, 37, 37, 37, 37, 37, 37, 18, 37, 37, 37, 37, 55, 55, 55, 55, 55,\n",
              "       55, 55, 55, 55, 55, 55,  7, 55, 55, 55, 55, 55, 17,  2, 17, 24, 24,\n",
              "       21, 17, 17, 17, 17, 17, 17, 15,  2,  2,  2,  2, 14,  2,  2,  2,  2,\n",
              "        2,  2,  2, 47, 47, 47, 47, 47, 47, 47, 47, 47, 58, 47, 47, 47, 54,\n",
              "       54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 21, 21, 21, 21, 21, 21, 21,\n",
              "       21, 21, 21, 21, 21, 34, 27, 34, 34, 34, 34, 34, 34, 34, 23, 23, 23,\n",
              "       23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 10, 10, 10, 10,  2, 10, 10,\n",
              "       10, 10, 10, 10, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
              "       28, 28, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,  7,  7,  7,\n",
              "        7,  7,  7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4, 48, 48, 48, 48, 48,\n",
              "       48, 48, 48, 48, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
              "       32, 32, 32, 12, 12, 12, 12, 12, 12, 12, 12, 22, 22, 22, 22, 22, 22,\n",
              "       22, 22, 22, 22, 22, 22, 22, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38,\n",
              "       38, 38, 38, 36, 36, 36, 36, 36, 36, 47, 36, 36, 36, 36, 52, 36, 36,\n",
              "       36, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 50, 50, 50, 50, 50,\n",
              "       50, 23, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 14,\n",
              "       14,  4, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "       15, 24, 24, 24, 24, 24, 24, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
              "       13, 13, 29, 29, 29, 23, 29, 29, 25, 29, 29, 14, 51, 29, 29, 29, 29,\n",
              "       29, 10, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  9,  9,  9,  9,  9,  9,  9,\n",
              "        9,  9, 49, 24, 49, 49, 49, 49, 49, 49, 49, 49, 49, 27, 27, 27, 27,\n",
              "       27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 42, 42, 42, 42, 42, 42, 42,\n",
              "       42, 42, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 41, 41, 41, 41, 41,\n",
              "       14, 41, 41, 41, 41, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57,\n",
              "       57, 57, 57, 57, 57,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
              "        8,  8, 35, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
              "       33, 33, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31,\n",
              "       31, 31, 31, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
              "       16, 16, 16, 16, 16, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
              "       30, 30, 30, 30, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
              "       39, 39])"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df = pd.DataFrame({\n",
        "    'Predicted labels before feature engineering': y_pred_test,\n",
        "    'Predicted labels after feature engineering': y_pred_test_fe,\n",
        "    'No. of new features': x_test_trf.shape[1]\n",
        "})\n",
        "\n",
        "\n",
        "for i in range(x_test_trf.shape[1]):\n",
        "    output_df[f'New feature {i+1}'] = x_test_trf.iloc[:, i]\n",
        "output_df\n",
        "output_df.to_csv('/content/drive/MyDrive/Colab Notebooks/190294K_label_1.csv',index=False)"
      ],
      "metadata": {
        "id": "RHN82kKCWq_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Label 2**"
      ],
      "metadata": {
        "id": "mH20XwH5HW8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without Feature Engineering"
      ],
      "metadata": {
        "id": "rXxeafdgHdSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[L2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "NB40NmZSHaue",
        "outputId": "a1fc25d9-3493-41eb-84d6-a2f93398433f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "0      -1.478075  -0.919153  -0.122854   0.190992   0.532721   0.083195   \n",
              "1      -0.164468  -0.168904   0.707648   0.863136   0.500324   0.655473   \n",
              "2      -1.104839  -0.495742   0.280910   0.694052   0.127613  -0.383403   \n",
              "3      -0.003102  -1.363269   0.554493  -0.203880   0.627494   0.006706   \n",
              "4      -0.245420  -0.128128  -0.890594   0.327789   0.215869   0.411213   \n",
              "...          ...        ...        ...        ...        ...        ...   \n",
              "28035   0.041445   1.189802  -0.142396   0.022144   2.639956  -0.065099   \n",
              "28036   1.222926  -0.535411   0.059296  -0.011324   0.280107  -0.266280   \n",
              "28037   1.003279  -0.017977   0.123935   0.312931   1.068010   0.212752   \n",
              "28038  -0.612983  -0.009674   0.017086  -0.612319   0.888715  -0.587050   \n",
              "28039   0.767063  -0.207868   0.467882  -0.431492   0.961490  -0.453202   \n",
              "\n",
              "       feature_7  feature_8  feature_9  feature_10  ...  feature_247  \\\n",
              "0      -0.413296   1.618364  -0.361684    0.922091  ...     0.392840   \n",
              "1       0.367621   0.459122  -0.115466   -0.415692  ...    -0.887951   \n",
              "2       0.115028  -0.106487  -0.438117    0.603185  ...     0.622465   \n",
              "3       0.805259   0.530926  -1.246632    0.955617  ...    -0.419594   \n",
              "4      -1.192756   0.616893   0.049771   -0.185977  ...    -0.281914   \n",
              "...          ...        ...        ...         ...  ...          ...   \n",
              "28035  -0.975244   0.167776   1.201813    0.556369  ...     0.690244   \n",
              "28036   0.760567  -1.634607  -0.124961    0.086491  ...     0.701165   \n",
              "28037   0.237290  -0.049874   0.227514    0.621372  ...     0.351412   \n",
              "28038   0.130273  -0.873496   0.217626   -0.735412  ...     0.483689   \n",
              "28039   0.601624   0.916398  -1.017462    1.542311  ...     0.094080   \n",
              "\n",
              "       feature_248  feature_249  feature_250  feature_251  feature_252  \\\n",
              "0        -0.528180    -0.083242     0.600690    -0.443301     1.484652   \n",
              "1         0.093141    -0.719624    -0.092054     0.931119     0.278431   \n",
              "2         0.366905     0.719441     0.564372     0.207672     0.503795   \n",
              "3        -0.093203    -0.039681     0.264457     0.819096    -0.890674   \n",
              "4        -0.918900     0.965921     0.754784    -0.610062     0.596708   \n",
              "...            ...          ...          ...          ...          ...   \n",
              "28035    -0.160700    -0.540798     1.254211     0.560265    -0.774734   \n",
              "28036    -0.435428    -0.044028     0.884075    -0.136116     0.039582   \n",
              "28037    -0.182745    -0.401442    -0.955139     0.843807    -1.398489   \n",
              "28038     0.306146     0.653486     0.231333     0.533451    -0.433915   \n",
              "28039    -0.089739    -1.348772    -0.404091     0.967211    -0.811067   \n",
              "\n",
              "       feature_253  feature_254  feature_255  feature_256  \n",
              "0        -0.585782    -1.040437     0.195293     0.225768  \n",
              "1         0.047282     0.229236    -0.578322    -0.212124  \n",
              "2         0.031109    -0.460085    -0.524868    -0.352231  \n",
              "3         0.827678    -0.375850    -0.319669    -0.476607  \n",
              "4         0.563620    -0.187139    -0.058229     0.425574  \n",
              "...            ...          ...          ...          ...  \n",
              "28035    -0.723551     0.918781     0.566787     0.445773  \n",
              "28036    -0.155878    -0.308519     0.898501    -0.277834  \n",
              "28037     0.771168     1.392149    -0.216609    -0.202054  \n",
              "28038     0.081457    -0.178080    -1.037466    -0.070564  \n",
              "28039     1.063342     1.254260    -0.026932    -1.241248  \n",
              "\n",
              "[28040 rows x 256 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5270b14-4c1b-44c9-852b-d9772fa79cb3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_247</th>\n",
              "      <th>feature_248</th>\n",
              "      <th>feature_249</th>\n",
              "      <th>feature_250</th>\n",
              "      <th>feature_251</th>\n",
              "      <th>feature_252</th>\n",
              "      <th>feature_253</th>\n",
              "      <th>feature_254</th>\n",
              "      <th>feature_255</th>\n",
              "      <th>feature_256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.478075</td>\n",
              "      <td>-0.919153</td>\n",
              "      <td>-0.122854</td>\n",
              "      <td>0.190992</td>\n",
              "      <td>0.532721</td>\n",
              "      <td>0.083195</td>\n",
              "      <td>-0.413296</td>\n",
              "      <td>1.618364</td>\n",
              "      <td>-0.361684</td>\n",
              "      <td>0.922091</td>\n",
              "      <td>...</td>\n",
              "      <td>0.392840</td>\n",
              "      <td>-0.528180</td>\n",
              "      <td>-0.083242</td>\n",
              "      <td>0.600690</td>\n",
              "      <td>-0.443301</td>\n",
              "      <td>1.484652</td>\n",
              "      <td>-0.585782</td>\n",
              "      <td>-1.040437</td>\n",
              "      <td>0.195293</td>\n",
              "      <td>0.225768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.164468</td>\n",
              "      <td>-0.168904</td>\n",
              "      <td>0.707648</td>\n",
              "      <td>0.863136</td>\n",
              "      <td>0.500324</td>\n",
              "      <td>0.655473</td>\n",
              "      <td>0.367621</td>\n",
              "      <td>0.459122</td>\n",
              "      <td>-0.115466</td>\n",
              "      <td>-0.415692</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.887951</td>\n",
              "      <td>0.093141</td>\n",
              "      <td>-0.719624</td>\n",
              "      <td>-0.092054</td>\n",
              "      <td>0.931119</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.047282</td>\n",
              "      <td>0.229236</td>\n",
              "      <td>-0.578322</td>\n",
              "      <td>-0.212124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.104839</td>\n",
              "      <td>-0.495742</td>\n",
              "      <td>0.280910</td>\n",
              "      <td>0.694052</td>\n",
              "      <td>0.127613</td>\n",
              "      <td>-0.383403</td>\n",
              "      <td>0.115028</td>\n",
              "      <td>-0.106487</td>\n",
              "      <td>-0.438117</td>\n",
              "      <td>0.603185</td>\n",
              "      <td>...</td>\n",
              "      <td>0.622465</td>\n",
              "      <td>0.366905</td>\n",
              "      <td>0.719441</td>\n",
              "      <td>0.564372</td>\n",
              "      <td>0.207672</td>\n",
              "      <td>0.503795</td>\n",
              "      <td>0.031109</td>\n",
              "      <td>-0.460085</td>\n",
              "      <td>-0.524868</td>\n",
              "      <td>-0.352231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.003102</td>\n",
              "      <td>-1.363269</td>\n",
              "      <td>0.554493</td>\n",
              "      <td>-0.203880</td>\n",
              "      <td>0.627494</td>\n",
              "      <td>0.006706</td>\n",
              "      <td>0.805259</td>\n",
              "      <td>0.530926</td>\n",
              "      <td>-1.246632</td>\n",
              "      <td>0.955617</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.419594</td>\n",
              "      <td>-0.093203</td>\n",
              "      <td>-0.039681</td>\n",
              "      <td>0.264457</td>\n",
              "      <td>0.819096</td>\n",
              "      <td>-0.890674</td>\n",
              "      <td>0.827678</td>\n",
              "      <td>-0.375850</td>\n",
              "      <td>-0.319669</td>\n",
              "      <td>-0.476607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.245420</td>\n",
              "      <td>-0.128128</td>\n",
              "      <td>-0.890594</td>\n",
              "      <td>0.327789</td>\n",
              "      <td>0.215869</td>\n",
              "      <td>0.411213</td>\n",
              "      <td>-1.192756</td>\n",
              "      <td>0.616893</td>\n",
              "      <td>0.049771</td>\n",
              "      <td>-0.185977</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.281914</td>\n",
              "      <td>-0.918900</td>\n",
              "      <td>0.965921</td>\n",
              "      <td>0.754784</td>\n",
              "      <td>-0.610062</td>\n",
              "      <td>0.596708</td>\n",
              "      <td>0.563620</td>\n",
              "      <td>-0.187139</td>\n",
              "      <td>-0.058229</td>\n",
              "      <td>0.425574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28035</th>\n",
              "      <td>0.041445</td>\n",
              "      <td>1.189802</td>\n",
              "      <td>-0.142396</td>\n",
              "      <td>0.022144</td>\n",
              "      <td>2.639956</td>\n",
              "      <td>-0.065099</td>\n",
              "      <td>-0.975244</td>\n",
              "      <td>0.167776</td>\n",
              "      <td>1.201813</td>\n",
              "      <td>0.556369</td>\n",
              "      <td>...</td>\n",
              "      <td>0.690244</td>\n",
              "      <td>-0.160700</td>\n",
              "      <td>-0.540798</td>\n",
              "      <td>1.254211</td>\n",
              "      <td>0.560265</td>\n",
              "      <td>-0.774734</td>\n",
              "      <td>-0.723551</td>\n",
              "      <td>0.918781</td>\n",
              "      <td>0.566787</td>\n",
              "      <td>0.445773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28036</th>\n",
              "      <td>1.222926</td>\n",
              "      <td>-0.535411</td>\n",
              "      <td>0.059296</td>\n",
              "      <td>-0.011324</td>\n",
              "      <td>0.280107</td>\n",
              "      <td>-0.266280</td>\n",
              "      <td>0.760567</td>\n",
              "      <td>-1.634607</td>\n",
              "      <td>-0.124961</td>\n",
              "      <td>0.086491</td>\n",
              "      <td>...</td>\n",
              "      <td>0.701165</td>\n",
              "      <td>-0.435428</td>\n",
              "      <td>-0.044028</td>\n",
              "      <td>0.884075</td>\n",
              "      <td>-0.136116</td>\n",
              "      <td>0.039582</td>\n",
              "      <td>-0.155878</td>\n",
              "      <td>-0.308519</td>\n",
              "      <td>0.898501</td>\n",
              "      <td>-0.277834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28037</th>\n",
              "      <td>1.003279</td>\n",
              "      <td>-0.017977</td>\n",
              "      <td>0.123935</td>\n",
              "      <td>0.312931</td>\n",
              "      <td>1.068010</td>\n",
              "      <td>0.212752</td>\n",
              "      <td>0.237290</td>\n",
              "      <td>-0.049874</td>\n",
              "      <td>0.227514</td>\n",
              "      <td>0.621372</td>\n",
              "      <td>...</td>\n",
              "      <td>0.351412</td>\n",
              "      <td>-0.182745</td>\n",
              "      <td>-0.401442</td>\n",
              "      <td>-0.955139</td>\n",
              "      <td>0.843807</td>\n",
              "      <td>-1.398489</td>\n",
              "      <td>0.771168</td>\n",
              "      <td>1.392149</td>\n",
              "      <td>-0.216609</td>\n",
              "      <td>-0.202054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28038</th>\n",
              "      <td>-0.612983</td>\n",
              "      <td>-0.009674</td>\n",
              "      <td>0.017086</td>\n",
              "      <td>-0.612319</td>\n",
              "      <td>0.888715</td>\n",
              "      <td>-0.587050</td>\n",
              "      <td>0.130273</td>\n",
              "      <td>-0.873496</td>\n",
              "      <td>0.217626</td>\n",
              "      <td>-0.735412</td>\n",
              "      <td>...</td>\n",
              "      <td>0.483689</td>\n",
              "      <td>0.306146</td>\n",
              "      <td>0.653486</td>\n",
              "      <td>0.231333</td>\n",
              "      <td>0.533451</td>\n",
              "      <td>-0.433915</td>\n",
              "      <td>0.081457</td>\n",
              "      <td>-0.178080</td>\n",
              "      <td>-1.037466</td>\n",
              "      <td>-0.070564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28039</th>\n",
              "      <td>0.767063</td>\n",
              "      <td>-0.207868</td>\n",
              "      <td>0.467882</td>\n",
              "      <td>-0.431492</td>\n",
              "      <td>0.961490</td>\n",
              "      <td>-0.453202</td>\n",
              "      <td>0.601624</td>\n",
              "      <td>0.916398</td>\n",
              "      <td>-1.017462</td>\n",
              "      <td>1.542311</td>\n",
              "      <td>...</td>\n",
              "      <td>0.094080</td>\n",
              "      <td>-0.089739</td>\n",
              "      <td>-1.348772</td>\n",
              "      <td>-0.404091</td>\n",
              "      <td>0.967211</td>\n",
              "      <td>-0.811067</td>\n",
              "      <td>1.063342</td>\n",
              "      <td>1.254260</td>\n",
              "      <td>-0.026932</td>\n",
              "      <td>-1.241248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28040 rows × 256 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5270b14-4c1b-44c9-852b-d9772fa79cb3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5270b14-4c1b-44c9-852b-d9772fa79cb3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5270b14-4c1b-44c9-852b-d9772fa79cb3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-947bf0a2-334a-46b7-afeb-f9df5e95a5c8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-947bf0a2-334a-46b7-afeb-f9df5e95a5c8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-947bf0a2-334a-46b7-afeb-f9df5e95a5c8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model to predict label_2\n",
        "from sklearn import svm\n",
        "\n",
        "clf = svm.SVC(kernel='linear')\n",
        "\n",
        "clf.fit(x_train[L2], y_train[L2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "mFZHFUygHxFm",
        "outputId": "6db18c7f-9d3e-4d90-aa9c-f68b24ac102a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-23 {color: black;background-color: white;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "y_pred_2 = clf.predict(x_valid[L2]) # Predicting the validation data set"
      ],
      "metadata": {
        "id": "fXYa5Z5lIMto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy of the validation data set\n",
        "print(metrics.confusion_matrix(y_valid[L2], y_pred_2))\n",
        "print(metrics.accuracy_score(y_valid[L2], y_pred_2))\n",
        "print(metrics.precision_score(y_valid[L2], y_pred_2, average='weighted'))\n",
        "print(metrics.recall_score(y_valid[L2], y_pred_2, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQY4gw1xIWZo",
        "outputId": "409d1b0a-5a51-4708-e69d-5656a4ef4e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[34  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 60  1  5  4  1  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 1  0 40  0  4  0  1  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 1  8  1 65  1  0  0  0  2  1  0  0  0  0  0  0  0]\n",
            " [ 0  2  2  4 99  4  0  1  0  3  0  0  0  0  0  0  0]\n",
            " [ 0  2  3  1  3 69  0  1  1  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  3  2 41  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 2  1  0  0  1  0  0 41  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  2  1  2  0  0 43  0  0  0  0  0  0  0  0]\n",
            " [ 1  0  0  3  2  2  0  0  1 55  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  0 29  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 18]]\n",
            "0.8817934782608695\n",
            "0.8839786971807817\n",
            "0.8817934782608695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting the label_3 of the test data set\n",
        "y_pred_test = clf.predict(x_test[L2])"
      ],
      "metadata": {
        "id": "sfuP-igpoI54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpDuDJS6rQoI",
        "outputId": "06d90e5a-6943-446e-bc7c-7d2c7f77152b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([27., 30., 30., 25., 27., 30., 25., 27., 25., 25., 25., 25., 25.,\n",
              "       25., 25., 25., 25., 25., 27., 23., 27., 27., 27., 27., 24., 27.,\n",
              "       23., 23., 27., 23., 23., 23., 23., 25., 23., 25., 23., 23., 23.,\n",
              "       23., 23., 23., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33.,\n",
              "       33., 33., 34., 34., 34., 34., 34., 34., 34., 34., 34., 34., 34.,\n",
              "       22., 22., 22., 22., 23., 22., 26., 22., 22., 22., 30., 30., 30.,\n",
              "       30., 30., 25., 30., 30., 30., 30., 30., 30., 30., 33., 30., 30.,\n",
              "       30., 27., 30., 30., 26., 26., 26., 26., 26., 26., 26., 26., 26.,\n",
              "       26., 26., 26., 29., 26., 26., 26., 26., 26., 24., 24., 24., 26.,\n",
              "       24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 31.,\n",
              "       24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 31., 31.,\n",
              "       31., 31., 31., 31., 31., 31., 31., 31., 26., 26., 26., 26., 26.,\n",
              "       26., 26., 26., 26., 26., 26., 26., 29., 26., 26., 31., 31., 31.,\n",
              "       31., 22., 34., 31., 31., 31., 31., 31., 22., 29., 29., 29., 29.,\n",
              "       29., 29., 29., 61., 61., 61., 61., 61., 61., 61., 61., 61., 61.,\n",
              "       61., 61., 61., 61., 27., 27., 27., 27., 27., 27., 26., 27., 27.,\n",
              "       27., 27., 27., 27., 27., 27., 27., 27., 23., 23., 23., 23., 23.,\n",
              "       26., 23., 23., 23., 23., 23., 29., 23., 23., 23., 23., 26., 26.,\n",
              "       26., 26., 26., 26., 26., 26., 26., 26., 26., 26., 26., 26., 25.,\n",
              "       25., 25., 25., 25., 25., 25., 25., 25., 25., 25., 25., 23., 23.,\n",
              "       31., 23., 23., 23., 27., 23., 23., 31., 23., 23., 23., 27., 24.,\n",
              "       27., 27., 27., 27., 27., 24., 27., 27., 27., 26., 26., 26., 26.,\n",
              "       26., 26., 26., 26., 26., 26., 31., 27., 25., 25., 25., 25., 25.,\n",
              "       25., 25., 25., 25., 28., 28., 28., 28., 28., 28., 28., 28., 28.,\n",
              "       28., 28., 28., 28., 36., 36., 36., 36., 36., 36., 36., 36., 36.,\n",
              "       36., 36., 28., 28., 28., 28., 28., 28., 28., 28., 28., 28., 28.,\n",
              "       28., 28., 28., 31., 25., 25., 25., 23., 25., 25., 25., 25., 25.,\n",
              "       25., 25., 25., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27.,\n",
              "       25., 25., 25., 25., 25., 25., 25., 25., 25., 25., 25., 25., 23.,\n",
              "       27., 23., 23., 31., 23., 23., 23., 23., 23., 26., 26., 26., 26.,\n",
              "       26., 26., 26., 26., 26., 23., 23., 23., 23., 23., 23., 23., 23.,\n",
              "       23., 23., 26., 23., 23., 23., 23., 26., 26., 26., 22., 26., 26.,\n",
              "       26., 26., 26., 33., 33., 33., 33., 33., 33., 33., 33., 24., 33.,\n",
              "       33., 33., 33., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "       32., 32., 32., 22., 22., 22., 22., 22., 22., 22., 22., 22., 22.,\n",
              "       22., 22., 22., 22., 22., 31., 24., 31., 31., 22., 31., 31., 24.,\n",
              "       31., 31., 31., 24., 24., 26., 24., 24., 24., 24., 23., 24., 24.,\n",
              "       24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 31., 31.,\n",
              "       41., 31., 31., 31., 31., 28., 28., 28., 28., 28., 26., 28., 28.,\n",
              "       28., 28., 28., 28., 26., 26., 26., 26., 26., 26., 27., 27., 27.,\n",
              "       27., 27., 27., 25., 27., 27., 26., 27., 27., 23., 23., 23., 26.,\n",
              "       23., 23., 22., 23., 24., 24., 24., 23., 23., 23., 26., 23., 25.,\n",
              "       25., 25., 25., 25., 25., 25., 25., 25., 25., 25., 23., 28., 25.,\n",
              "       25., 25., 30., 30., 26., 30., 30., 30., 30., 30., 30., 30., 35.,\n",
              "       35., 35., 35., 35., 35., 35., 35., 35., 26., 26., 26., 26., 26.,\n",
              "       23., 26., 26., 26., 26., 26., 31., 30., 31., 31., 31., 31., 31.,\n",
              "       31., 31., 31., 31., 31., 31., 31., 29., 27., 29., 24., 29., 26.,\n",
              "       28., 29., 29., 22., 22., 22., 22., 22., 22., 22., 22., 22., 22.,\n",
              "       30., 30., 30., 30., 30., 25., 30., 30., 30., 30., 27., 27., 27.,\n",
              "       27., 27., 27., 31., 27., 27., 27., 27., 22., 27., 27., 27., 27.,\n",
              "       27., 41., 41., 41., 41., 41., 41., 41., 41., 41., 41., 41., 41.,\n",
              "       41., 41., 26., 26., 26., 26., 26., 26., 26., 26., 26., 26., 26.,\n",
              "       26., 26., 26., 26., 26., 26., 26., 26., 25., 26., 26., 25., 26.,\n",
              "       26., 26., 26., 26., 26., 26., 26., 26., 25., 26., 26., 30., 30.,\n",
              "       23., 30., 30., 30., 27., 30., 30., 30., 25., 30., 30., 30., 30.,\n",
              "       31., 30., 30., 30., 28., 26., 28., 26., 28., 27., 28., 28., 26.,\n",
              "       28., 28., 28., 26., 28., 28., 28., 29., 29., 29., 29., 29., 29.,\n",
              "       26., 29., 29., 29., 23., 26., 29., 29., 29.])"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With Feature Engineering"
      ],
      "metadata": {
        "id": "NarI2cEQrWcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsRegressor  # Import KNeighborsRegressor\n",
        "from sklearn import metrics\n",
        "\n",
        "selector = SelectKBest(f_classif, k=50)\n",
        "x_train_new = selector.fit_transform(x_train[L2], y_train[L2])\n"
      ],
      "metadata": {
        "id": "feSYXMonrbGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying PCA to selected features\n",
        "pca = PCA(n_components=0.95, svd_solver='full')\n",
        "x_train_pca = pca.fit_transform(x_train_new)\n",
        "print(\"Shape after PCA: \", x_train_pca.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2krXP3CarneI",
        "outputId": "c4c46bc7-e24f-4afe-f476-ad324659423a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after PCA:  (28040, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a validation set with feature transformations\n",
        "x_valid_new = selector.transform(x_valid[L2])\n",
        "x_valid_pca = pca.transform(x_valid_new)\n",
        "\n",
        "x_test_new = selector.transform(x_test[L2])\n",
        "x_test_pca = pca.transform(x_test_new)\n"
      ],
      "metadata": {
        "id": "0-_pI0T7rv07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a KNN regressor\n",
        "regressor = KNeighborsRegressor(n_neighbors=5)\n",
        "\n",
        "# Fitting the KNN regressor\n",
        "regressor.fit(x_train_pca, y_train[L2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "8k5vRC2dsGAt",
        "outputId": "f8bbc2fb-3161-4691-f02c-9706b861be4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsRegressor()"
            ],
            "text/html": [
              "<style>#sk-container-id-24 {color: black;background-color: white;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation set\n",
        "y_pred = regressor.predict(x_valid_pca)\n",
        "\n",
        "# KNN regressor's performance\n",
        "print(\"Mean Absolute Error:\", metrics.mean_absolute_error(y_valid[L2], y_pred))\n",
        "print(\"Mean Squared Error:\", metrics.mean_squared_error(y_valid[L2], y_pred))\n",
        "print(\"R-squared:\", metrics.r2_score(y_valid[L2], y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DYNkJ42sSzI",
        "outputId": "3647a4ce-adc6-4844-de3e-db97b03dda39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 0.3885869565217391\n",
            "Mean Squared Error: 2.672717391304347\n",
            "R-squared: 0.9370134013334379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred_test_fe = regressor.predict(x_test_pca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0DMyW08snVc",
        "outputId": "b0b0e372-9e99-4bfb-f9d1-5947966e86b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted values before feature engineering: [26.6 27.8 28.2 30.2 27.8 26.  25.  25.  25.  25.  25.  25.  25.  25.\n",
            " 25.  25.  26.2 25.  27.  27.  27.  27.  27.  27.  27.  25.2 23.  24.4\n",
            " 23.6 23.  23.6 24.2 25.  23.  25.6 24.  25.2 23.  24.8 23.6 23.  23.\n",
            " 32.4 33.  33.  33.  33.  33.  33.  33.  33.  33.  33.  33.  34.  26.8\n",
            " 34.  32.6 34.  34.  34.  34.  34.  34.  34.  22.  22.  22.  22.  22.\n",
            " 22.  22.  22.  22.  22.  30.  30.  30.  30.  30.  30.  30.  30.  29.4\n",
            " 30.6 30.  30.  36.2 30.6 27.4 30.  30.  30.  30.  30.  28.  29.2 24.6\n",
            " 26.  26.  26.  26.6 26.  25.2 26.  26.  26.  26.  26.  26.  26.  26.\n",
            " 24.4 23.8 24.  24.  24.  24.  24.  24.  24.  24.  24.  24.  24.  24.\n",
            " 24.  25.6 24.  24.  24.  24.  24.  24.  24.  23.6 24.  25.  27.4 24.\n",
            " 24.  31.  31.  31.  31.  31.  31.  31.  31.  31.  31.  26.  26.  26.\n",
            " 26.  26.  26.  26.  25.4 26.  26.  25.  26.  26.  26.  26.  31.  29.2\n",
            " 31.  31.  31.  33.4 31.  31.  31.  29.2 31.  27.6 29.  29.  29.  29.\n",
            " 29.  29.  29.  39.4 46.6 61.  61.  61.  61.  61.  61.  53.4 61.  61.\n",
            " 45.8 61.  61.  27.  26.2 27.  27.  27.  27.  27.  27.  27.  26.8 27.\n",
            " 26.6 26.4 27.  27.  27.  27.  23.  23.  23.  23.  23.  23.6 23.  23.\n",
            " 23.  23.  23.  26.2 26.2 23.  23.  46.8 23.  26.  26.  26.  25.4 26.\n",
            " 25.4 26.  24.6 25.8 26.  25.4 26.  26.  25.  25.  25.  25.  25.  25.\n",
            " 25.  25.  30.6 32.4 25.  25.  23.  23.  23.  23.  23.  23.  22.8 23.\n",
            " 23.  22.8 24.6 23.  23.  27.  27.  27.  27.  27.6 27.  27.  26.2 28.6\n",
            " 27.  27.  26.  26.  26.  30.6 26.  26.  26.  26.  25.4 26.4 26.  26.\n",
            " 25.  26.  25.  25.  25.  25.  25.  25.  25.  26.4 28.  30.6 28.  28.\n",
            " 28.  28.  28.  27.4 28.  28.  28.6 28.  36.  36.  36.  36.  36.  36.\n",
            " 36.  36.  36.  36.  36.  28.  28.  28.  28.  28.  28.  28.  28.  28.\n",
            " 28.  28.  28.  28.  28.  28.  25.  25.  25.6 23.8 25.8 25.  25.  25.\n",
            " 25.  26.2 25.  25.  27.  27.  27.  27.  27.  27.  27.  27.  26.8 28.2\n",
            " 25.  25.  25.  25.  25.  25.  25.  25.  25.  25.  25.  25.  23.  23.\n",
            " 23.  23.  23.  23.  23.  23.  23.  23.  26.  26.  26.  26.  26.  26.\n",
            " 26.6 26.  26.  23.  24.8 24.6 23.  23.  23.  23.  23.  23.  23.  23.6\n",
            " 23.  23.  23.  23.  23.  26.  26.  26.  26.  26.  26.  26.  27.4 33.\n",
            " 33.  33.  33.  33.  33.  33.  33.  33.  33.  33.  31.6 33.  32.  32.\n",
            " 31.6 28.2 32.  32.  30.6 32.  32.  32.  30.8 32.  32.  22.8 22.  22.\n",
            " 23.4 22.  22.  22.6 22.  22.  22.  22.  22.  22.  22.  22.  31.  29.2\n",
            " 31.  31.  31.  31.  31.  31.  31.  31.  31.  26.  25.  28.4 24.  24.\n",
            " 24.  24.2 24.  24.  24.  24.  24.2 24.  24.6 24.  24.  24.  24.8 24.\n",
            " 24.  24.  30.4 31.  29.8 30.  31.  29.4 27.6 28.  28.  28.  28.  28.\n",
            " 28.  28.  28.4 28.  28.  28.2 28.  26.  25.2 26.  26.  26.  26.  27.\n",
            " 27.  27.  27.  27.  27.  27.  27.  32.4 27.  27.  27.  25.  23.8 24.8\n",
            " 23.6 24.6 25.8 23.4 23.  26.2 24.  23.6 23.  23.  23.  24.6 30.2 26.8\n",
            " 25.  28.6 25.  25.  25.4 31.4 25.  25.  25.  24.6 25.  27.8 25.  25.\n",
            " 25.  30.  30.  30.  30.  27.6 30.  30.  30.  30.  30.  35.  35.  35.\n",
            " 35.  35.  35.  35.  35.  35.  26.  25.8 26.  26.  26.  26.2 26.  26.\n",
            " 26.  26.  26.  31.2 29.2 31.  31.  31.  31.  30.  31.  30.  31.  31.\n",
            " 30.2 31.  31.  29.  28.6 29.  26.6 29.  29.  28.8 29.  29.  22.  22.\n",
            " 22.  22.  22.  25.2 22.  22.  22.  22.  30.  30.  30.  30.  30.  30.\n",
            " 30.  29.6 30.  30.  27.  27.  27.  27.  32.6 27.  27.  27.  27.4 27.\n",
            " 27.  27.  27.  27.  27.  27.8 27.  41.  41.  41.  41.  35.4 41.  41.\n",
            " 41.  41.  41.  41.  41.  41.  41.  26.2 26.  26.  26.4 25.6 26.  27.2\n",
            " 26.  26.  25.4 26.6 25.4 26.  27.2 26.  26.  26.4 26.  26.  26.  26.\n",
            " 24.8 26.8 26.  26.  27.4 26.  25.6 26.  26.4 26.  26.  26.  26.  25.\n",
            " 30.  30.  30.  30.  30.  30.  30.  30.  30.  30.  30.  30.  30.  30.\n",
            " 30.  26.4 29.  30.  30.  23.6 28.  28.  28.2 28.  28.2 28.  28.  27.6\n",
            " 28.  28.  27.6 28.  28.  28.  28.  25.8 29.  29.  29.  29.  29.  29.\n",
            " 29.  29.  28.6 25.4 28.4 29.  27.2 29. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df = pd.DataFrame({\n",
        "    'Predicted labels before feature engineering': y_pred_test,\n",
        "    'Predicted labels after feature engineering': y_pred_test_fe,\n",
        "    'No. of new features': x_test_pca.shape[1]\n",
        "})\n",
        "\n",
        "for i in range(x_test_pca.shape[1]):\n",
        "    output_df[f'New feature {i+1}'] = x_test_pca[:, i]\n",
        "output_df\n",
        "output_df.to_csv('/content/drive/MyDrive/Colab Notebooks/190294K_label_2.csv',index=False)"
      ],
      "metadata": {
        "id": "2793unUis8O5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Label 3**"
      ],
      "metadata": {
        "id": "fa4gO3VrNATH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without Feature Engineering"
      ],
      "metadata": {
        "id": "7ad-A6ImNCpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[L3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "2VjsNBBBNFE_",
        "outputId": "d6dac2bc-a4bc-4d7b-8e74-d4a47d71b688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "0      -1.309586   0.235701   0.943739   1.110687   0.493583  -0.232368   \n",
              "1      -1.144159  -0.295674   0.837377   2.514509  -0.718433   1.537233   \n",
              "2      -1.292525   0.186803  -0.330437   2.726045  -0.915203   1.013608   \n",
              "3       0.669594  -1.191524  -0.251777   0.560848   0.193810   0.728978   \n",
              "4      -1.345805   0.084043   0.418116   2.155265  -0.227710   1.064978   \n",
              "...          ...        ...        ...        ...        ...        ...   \n",
              "28515   0.043336   1.192542  -0.149975   0.011312   2.636595  -0.068369   \n",
              "28516   1.215430  -0.535137   0.051517  -0.021644   0.280856  -0.269055   \n",
              "28517   0.997528  -0.016963   0.116092   0.297648   1.067387   0.208798   \n",
              "28518  -0.605893  -0.008649   0.009349  -0.613440   0.888404  -0.589037   \n",
              "28519   0.763188  -0.207126   0.459697  -0.435380   0.961052  -0.455518   \n",
              "\n",
              "       feature_7  feature_8  feature_9  feature_10  ...  feature_247  \\\n",
              "0      -0.624554  -0.504571   0.132999    0.095217  ...     1.583006   \n",
              "1       0.286751  -0.431414   1.105227   -0.783768  ...     1.036040   \n",
              "2       1.247330  -1.564947   0.951931   -1.012765  ...     0.297848   \n",
              "3       0.931314   0.170499   1.527067    0.288711  ...     0.829376   \n",
              "4      -0.248008   0.090402   0.538791   -1.573073  ...     1.058010   \n",
              "...          ...        ...        ...         ...  ...          ...   \n",
              "28515  -0.978061   0.177880   1.175240    0.563477  ...     0.670030   \n",
              "28516   0.761116  -1.611506  -0.137716    0.093801  ...     0.680854   \n",
              "28517   0.236824  -0.038200   0.211088    0.628452  ...     0.334185   \n",
              "28518   0.129601  -0.855883   0.201302   -0.727748  ...     0.465296   \n",
              "28519   0.601866   0.921103  -1.020922    1.548995  ...     0.079121   \n",
              "\n",
              "       feature_248  feature_249  feature_250  feature_251  feature_252  \\\n",
              "0         1.101137    -0.786061     0.622750    -0.503841    -0.862208   \n",
              "1        -0.688550    -1.640606    -0.053767    -0.486404    -0.493145   \n",
              "2         0.303437    -2.323521    -0.182392    -0.006368     0.086269   \n",
              "3        -0.102070    -2.596694    -0.616500     0.544197     0.307588   \n",
              "4        -0.117040    -1.419770     0.362046    -0.435119    -0.786176   \n",
              "...            ...          ...          ...          ...          ...   \n",
              "28515    -0.158732    -0.525769     1.257927     0.567362    -0.776576   \n",
              "28516    -0.432984    -0.031154     0.887144    -0.127631     0.039676   \n",
              "28517    -0.180739    -0.387017    -0.955283     0.850339    -1.401814   \n",
              "28518     0.307306     0.663333     0.233262     0.540602    -0.434947   \n",
              "28519    -0.087894    -1.330237    -0.403272     0.973497    -0.812996   \n",
              "\n",
              "       feature_253  feature_254  feature_255  feature_256  \n",
              "0        -1.063657    -0.033389    -0.726253     0.785181  \n",
              "1        -1.293456    -0.320623     0.746471    -0.660619  \n",
              "2         0.762691     0.577715    -0.946525    -0.585987  \n",
              "3        -0.577020     0.401594    -1.154003     0.207497  \n",
              "4         0.068403    -0.787532     1.939043     0.183946  \n",
              "...            ...          ...          ...          ...  \n",
              "28515    -0.718924     0.924023     0.570760     0.442692  \n",
              "28516    -0.151647    -0.303670     0.903381    -0.282937  \n",
              "28517     0.774752     1.397541    -0.214777    -0.206945  \n",
              "28518     0.085522    -0.173189    -1.037877    -0.075089  \n",
              "28519     1.066722     1.259609    -0.024581    -1.249044  \n",
              "\n",
              "[28520 rows x 256 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1a004c8-6cd6-43a1-a737-b128557d295a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_247</th>\n",
              "      <th>feature_248</th>\n",
              "      <th>feature_249</th>\n",
              "      <th>feature_250</th>\n",
              "      <th>feature_251</th>\n",
              "      <th>feature_252</th>\n",
              "      <th>feature_253</th>\n",
              "      <th>feature_254</th>\n",
              "      <th>feature_255</th>\n",
              "      <th>feature_256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.309586</td>\n",
              "      <td>0.235701</td>\n",
              "      <td>0.943739</td>\n",
              "      <td>1.110687</td>\n",
              "      <td>0.493583</td>\n",
              "      <td>-0.232368</td>\n",
              "      <td>-0.624554</td>\n",
              "      <td>-0.504571</td>\n",
              "      <td>0.132999</td>\n",
              "      <td>0.095217</td>\n",
              "      <td>...</td>\n",
              "      <td>1.583006</td>\n",
              "      <td>1.101137</td>\n",
              "      <td>-0.786061</td>\n",
              "      <td>0.622750</td>\n",
              "      <td>-0.503841</td>\n",
              "      <td>-0.862208</td>\n",
              "      <td>-1.063657</td>\n",
              "      <td>-0.033389</td>\n",
              "      <td>-0.726253</td>\n",
              "      <td>0.785181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.144159</td>\n",
              "      <td>-0.295674</td>\n",
              "      <td>0.837377</td>\n",
              "      <td>2.514509</td>\n",
              "      <td>-0.718433</td>\n",
              "      <td>1.537233</td>\n",
              "      <td>0.286751</td>\n",
              "      <td>-0.431414</td>\n",
              "      <td>1.105227</td>\n",
              "      <td>-0.783768</td>\n",
              "      <td>...</td>\n",
              "      <td>1.036040</td>\n",
              "      <td>-0.688550</td>\n",
              "      <td>-1.640606</td>\n",
              "      <td>-0.053767</td>\n",
              "      <td>-0.486404</td>\n",
              "      <td>-0.493145</td>\n",
              "      <td>-1.293456</td>\n",
              "      <td>-0.320623</td>\n",
              "      <td>0.746471</td>\n",
              "      <td>-0.660619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.292525</td>\n",
              "      <td>0.186803</td>\n",
              "      <td>-0.330437</td>\n",
              "      <td>2.726045</td>\n",
              "      <td>-0.915203</td>\n",
              "      <td>1.013608</td>\n",
              "      <td>1.247330</td>\n",
              "      <td>-1.564947</td>\n",
              "      <td>0.951931</td>\n",
              "      <td>-1.012765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.297848</td>\n",
              "      <td>0.303437</td>\n",
              "      <td>-2.323521</td>\n",
              "      <td>-0.182392</td>\n",
              "      <td>-0.006368</td>\n",
              "      <td>0.086269</td>\n",
              "      <td>0.762691</td>\n",
              "      <td>0.577715</td>\n",
              "      <td>-0.946525</td>\n",
              "      <td>-0.585987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.669594</td>\n",
              "      <td>-1.191524</td>\n",
              "      <td>-0.251777</td>\n",
              "      <td>0.560848</td>\n",
              "      <td>0.193810</td>\n",
              "      <td>0.728978</td>\n",
              "      <td>0.931314</td>\n",
              "      <td>0.170499</td>\n",
              "      <td>1.527067</td>\n",
              "      <td>0.288711</td>\n",
              "      <td>...</td>\n",
              "      <td>0.829376</td>\n",
              "      <td>-0.102070</td>\n",
              "      <td>-2.596694</td>\n",
              "      <td>-0.616500</td>\n",
              "      <td>0.544197</td>\n",
              "      <td>0.307588</td>\n",
              "      <td>-0.577020</td>\n",
              "      <td>0.401594</td>\n",
              "      <td>-1.154003</td>\n",
              "      <td>0.207497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.345805</td>\n",
              "      <td>0.084043</td>\n",
              "      <td>0.418116</td>\n",
              "      <td>2.155265</td>\n",
              "      <td>-0.227710</td>\n",
              "      <td>1.064978</td>\n",
              "      <td>-0.248008</td>\n",
              "      <td>0.090402</td>\n",
              "      <td>0.538791</td>\n",
              "      <td>-1.573073</td>\n",
              "      <td>...</td>\n",
              "      <td>1.058010</td>\n",
              "      <td>-0.117040</td>\n",
              "      <td>-1.419770</td>\n",
              "      <td>0.362046</td>\n",
              "      <td>-0.435119</td>\n",
              "      <td>-0.786176</td>\n",
              "      <td>0.068403</td>\n",
              "      <td>-0.787532</td>\n",
              "      <td>1.939043</td>\n",
              "      <td>0.183946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28515</th>\n",
              "      <td>0.043336</td>\n",
              "      <td>1.192542</td>\n",
              "      <td>-0.149975</td>\n",
              "      <td>0.011312</td>\n",
              "      <td>2.636595</td>\n",
              "      <td>-0.068369</td>\n",
              "      <td>-0.978061</td>\n",
              "      <td>0.177880</td>\n",
              "      <td>1.175240</td>\n",
              "      <td>0.563477</td>\n",
              "      <td>...</td>\n",
              "      <td>0.670030</td>\n",
              "      <td>-0.158732</td>\n",
              "      <td>-0.525769</td>\n",
              "      <td>1.257927</td>\n",
              "      <td>0.567362</td>\n",
              "      <td>-0.776576</td>\n",
              "      <td>-0.718924</td>\n",
              "      <td>0.924023</td>\n",
              "      <td>0.570760</td>\n",
              "      <td>0.442692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28516</th>\n",
              "      <td>1.215430</td>\n",
              "      <td>-0.535137</td>\n",
              "      <td>0.051517</td>\n",
              "      <td>-0.021644</td>\n",
              "      <td>0.280856</td>\n",
              "      <td>-0.269055</td>\n",
              "      <td>0.761116</td>\n",
              "      <td>-1.611506</td>\n",
              "      <td>-0.137716</td>\n",
              "      <td>0.093801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.680854</td>\n",
              "      <td>-0.432984</td>\n",
              "      <td>-0.031154</td>\n",
              "      <td>0.887144</td>\n",
              "      <td>-0.127631</td>\n",
              "      <td>0.039676</td>\n",
              "      <td>-0.151647</td>\n",
              "      <td>-0.303670</td>\n",
              "      <td>0.903381</td>\n",
              "      <td>-0.282937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28517</th>\n",
              "      <td>0.997528</td>\n",
              "      <td>-0.016963</td>\n",
              "      <td>0.116092</td>\n",
              "      <td>0.297648</td>\n",
              "      <td>1.067387</td>\n",
              "      <td>0.208798</td>\n",
              "      <td>0.236824</td>\n",
              "      <td>-0.038200</td>\n",
              "      <td>0.211088</td>\n",
              "      <td>0.628452</td>\n",
              "      <td>...</td>\n",
              "      <td>0.334185</td>\n",
              "      <td>-0.180739</td>\n",
              "      <td>-0.387017</td>\n",
              "      <td>-0.955283</td>\n",
              "      <td>0.850339</td>\n",
              "      <td>-1.401814</td>\n",
              "      <td>0.774752</td>\n",
              "      <td>1.397541</td>\n",
              "      <td>-0.214777</td>\n",
              "      <td>-0.206945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28518</th>\n",
              "      <td>-0.605893</td>\n",
              "      <td>-0.008649</td>\n",
              "      <td>0.009349</td>\n",
              "      <td>-0.613440</td>\n",
              "      <td>0.888404</td>\n",
              "      <td>-0.589037</td>\n",
              "      <td>0.129601</td>\n",
              "      <td>-0.855883</td>\n",
              "      <td>0.201302</td>\n",
              "      <td>-0.727748</td>\n",
              "      <td>...</td>\n",
              "      <td>0.465296</td>\n",
              "      <td>0.307306</td>\n",
              "      <td>0.663333</td>\n",
              "      <td>0.233262</td>\n",
              "      <td>0.540602</td>\n",
              "      <td>-0.434947</td>\n",
              "      <td>0.085522</td>\n",
              "      <td>-0.173189</td>\n",
              "      <td>-1.037877</td>\n",
              "      <td>-0.075089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28519</th>\n",
              "      <td>0.763188</td>\n",
              "      <td>-0.207126</td>\n",
              "      <td>0.459697</td>\n",
              "      <td>-0.435380</td>\n",
              "      <td>0.961052</td>\n",
              "      <td>-0.455518</td>\n",
              "      <td>0.601866</td>\n",
              "      <td>0.921103</td>\n",
              "      <td>-1.020922</td>\n",
              "      <td>1.548995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.079121</td>\n",
              "      <td>-0.087894</td>\n",
              "      <td>-1.330237</td>\n",
              "      <td>-0.403272</td>\n",
              "      <td>0.973497</td>\n",
              "      <td>-0.812996</td>\n",
              "      <td>1.066722</td>\n",
              "      <td>1.259609</td>\n",
              "      <td>-0.024581</td>\n",
              "      <td>-1.249044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28520 rows × 256 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1a004c8-6cd6-43a1-a737-b128557d295a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b1a004c8-6cd6-43a1-a737-b128557d295a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b1a004c8-6cd6-43a1-a737-b128557d295a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ed8a6137-2aa9-4f7d-be6e-e152a577d7f9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed8a6137-2aa9-4f7d-be6e-e152a577d7f9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ed8a6137-2aa9-4f7d-be6e-e152a577d7f9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model to predict label_1\n",
        "from sklearn import svm\n",
        "\n",
        "clf = svm.SVC(kernel='linear')\n",
        "\n",
        "clf.fit(x_train[L3], y_train[L3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "20w6k9LLNK--",
        "outputId": "217f29d5-27bb-48e9-c122-efa5ee3044f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-25 {color: black;background-color: white;}#sk-container-id-25 pre{padding: 0;}#sk-container-id-25 div.sk-toggleable {background-color: white;}#sk-container-id-25 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-25 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-25 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-25 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-25 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-25 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-25 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-25 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-25 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-25 div.sk-item {position: relative;z-index: 1;}#sk-container-id-25 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-25 div.sk-item::before, #sk-container-id-25 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-25 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-25 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-25 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-25 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-25 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-25 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-25 div.sk-label-container {text-align: center;}#sk-container-id-25 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-25 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" checked><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "y_pred_3 = clf.predict(x_valid[L3]) # Predicting the validation data set"
      ],
      "metadata": {
        "id": "LUp2-kq-NTV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy of the validation data set\n",
        "print(metrics.confusion_matrix(y_valid[L3], y_pred_3))\n",
        "print(metrics.accuracy_score(y_valid[L3], y_pred_3))\n",
        "print(metrics.precision_score(y_valid[L3], y_pred_3, average='weighted'))\n",
        "print(metrics.recall_score(y_valid[L3], y_pred_3, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABh-xWv3Oq9v",
        "outputId": "2bb0d249-d06f-4bda-828b-f42d3bd2b15b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[142   0]\n",
            " [  1 607]]\n",
            "0.9986666666666667\n",
            "0.9986759906759908\n",
            "0.9986666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting the label_3 of the test data set\n",
        "y_pred_test = clf.predict(x_test[L3])"
      ],
      "metadata": {
        "id": "RmX_PgFCPIU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZGkqRfZPMY-",
        "outputId": "c52b01b6-61bb-4de2-a3db-138c44b60a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With Feature Engineering"
      ],
      "metadata": {
        "id": "jjoHWrh8PT6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# With  selectKBest method\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "selector =  SelectKBest(f_classif, k=10) #  with only using 10 features\n",
        "x_new_train = selector.fit_transform(x_train[L1], y_train[L1])\n",
        "x_new_valid = selector.transform(x_valid[L1])\n",
        "x_new_test = selector.transform(x_test[L1])\n",
        "print('shape training', x_new_train.shape)\n",
        "print('shape validation', x_new_valid.shape)\n",
        "print('shape test', x_new_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3bKfYuYPWZW",
        "outputId": "17fe5b32-efe8-4328-c862-19caecb4d202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape training (28520, 10)\n",
            "shape validation (750, 10)\n",
            "shape test (750, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(kernel='linear')\n",
        "\n",
        "clf.fit(x_new_train, y_train[L3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "XOrW4xF4XdUP",
        "outputId": "c82ac610-6039-446d-a0d0-3058d3443d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-26 {color: black;background-color: white;}#sk-container-id-26 pre{padding: 0;}#sk-container-id-26 div.sk-toggleable {background-color: white;}#sk-container-id-26 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-26 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-26 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-26 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-26 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-26 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-26 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-26 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-26 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-26 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-26 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-26 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-26 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-26 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-26 div.sk-item {position: relative;z-index: 1;}#sk-container-id-26 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-26 div.sk-item::before, #sk-container-id-26 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-26 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-26 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-26 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-26 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-26 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-26 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-26 div.sk-label-container {text-align: center;}#sk-container-id-26 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-26 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-26\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" checked><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_3 = clf.predict(selector.transform(x_valid[L3]))\n",
        "print(metrics.confusion_matrix(y_valid[L3], y_pred_3))\n",
        "print(metrics.accuracy_score(y_valid[L3], y_pred_3))\n",
        "print(metrics.precision_score(y_valid[L3], y_pred_3, average='weighted'))\n",
        "print(metrics.recall_score(y_valid[L3], y_pred_3, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0NvNnM4XfrH",
        "outputId": "540bf85b-03f8-4b32-b338-f29c323aa59d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[138   4]\n",
            " [ 12 596]]\n",
            "0.9786666666666667\n",
            "0.9794488888888888\n",
            "0.9786666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding PCA to the selectKBest results\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=0.95, svd_solver='full')\n",
        "pca.fit(x_new_train)\n",
        "x_train_trf = pd.DataFrame(pca.transform(x_new_train)) # transforming data to fit into pca\n",
        "x_valid_trf = pd.DataFrame(pca.transform(x_new_valid))\n",
        "x_test_trf = pd.DataFrame(pca.transform(x_new_test))\n",
        "print('Shape after PCA x_train : ', x_train_trf.shape)\n",
        "print('Shape after PCA x_valid : ', x_valid_trf.shape)\n",
        "print('Shape after PCA x_test : ', x_valid_trf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvfQ5sR-YBwe",
        "outputId": "66f65701-6bf3-463f-db5a-3f347dcfa487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after PCA x_train :  (28520, 8)\n",
            "Shape after PCA x_valid :  (750, 8)\n",
            "Shape after PCA x_test :  (750, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(kernel='linear')\n",
        "\n",
        "clf.fit(x_train_trf, y_train[L3])\n",
        "\n",
        "y_pred = clf.predict(x_valid_trf)\n",
        "print(metrics.confusion_matrix(y_valid[L3], y_pred))\n",
        "print(metrics.accuracy_score(y_valid[L3], y_pred))\n",
        "print(metrics.precision_score(y_valid[L3], y_pred, average='weighted'))\n",
        "print(metrics.recall_score(y_valid[L3], y_pred, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXYxNaeAYIy_",
        "outputId": "57d5967e-ea4c-493a-c0d1-076625dcc96e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[139   3]\n",
            " [ 12 596]]\n",
            "0.98\n",
            "0.9808935422171611\n",
            "0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting the test data\n",
        "y_pred_test_fe = clf.predict(x_test_trf)\n",
        "y_pred_test_fe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQj5AQdpYiaO",
        "outputId": "81f3df66-89c6-4cdc-8ca5-0285cd054adf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df = pd.DataFrame({\n",
        "    'Predicted labels before feature engineering': y_pred_test,\n",
        "    'Predicted labels after feature engineering': y_pred_test_fe,\n",
        "    'No. of new features': x_test_trf.shape[1]\n",
        "})\n",
        "\n",
        "\n",
        "for i in range(x_test_trf.shape[1]):\n",
        "    output_df[f'New feature {i+1}'] = x_test_trf.iloc[:, i]\n",
        "output_df\n",
        "output_df.to_csv('/content/drive/MyDrive/Colab Notebooks/190294K_label_3.csv',index=False)"
      ],
      "metadata": {
        "id": "2L-BbMdUbsqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For Label 4**"
      ],
      "metadata": {
        "id": "EQL7j9gYcAkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without Feature Engineering"
      ],
      "metadata": {
        "id": "W6O27McecJYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[L4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "3jZjDmJ4b_zH",
        "outputId": "6bc47c60-8e12-4144-91b3-f15509912a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "0      -1.309586   0.235701   0.943739   1.110687   0.493583  -0.232368   \n",
              "1      -1.144159  -0.295674   0.837377   2.514509  -0.718433   1.537233   \n",
              "2      -1.292525   0.186803  -0.330437   2.726045  -0.915203   1.013608   \n",
              "3       0.669594  -1.191524  -0.251777   0.560848   0.193810   0.728978   \n",
              "4      -1.345805   0.084043   0.418116   2.155265  -0.227710   1.064978   \n",
              "...          ...        ...        ...        ...        ...        ...   \n",
              "28515   0.043336   1.192542  -0.149975   0.011312   2.636595  -0.068369   \n",
              "28516   1.215430  -0.535137   0.051517  -0.021644   0.280856  -0.269055   \n",
              "28517   0.997528  -0.016963   0.116092   0.297648   1.067387   0.208798   \n",
              "28518  -0.605893  -0.008649   0.009349  -0.613440   0.888404  -0.589037   \n",
              "28519   0.763188  -0.207126   0.459697  -0.435380   0.961052  -0.455518   \n",
              "\n",
              "       feature_7  feature_8  feature_9  feature_10  ...  feature_247  \\\n",
              "0      -0.624554  -0.504571   0.132999    0.095217  ...     1.583006   \n",
              "1       0.286751  -0.431414   1.105227   -0.783768  ...     1.036040   \n",
              "2       1.247330  -1.564947   0.951931   -1.012765  ...     0.297848   \n",
              "3       0.931314   0.170499   1.527067    0.288711  ...     0.829376   \n",
              "4      -0.248008   0.090402   0.538791   -1.573073  ...     1.058010   \n",
              "...          ...        ...        ...         ...  ...          ...   \n",
              "28515  -0.978061   0.177880   1.175240    0.563477  ...     0.670030   \n",
              "28516   0.761116  -1.611506  -0.137716    0.093801  ...     0.680854   \n",
              "28517   0.236824  -0.038200   0.211088    0.628452  ...     0.334185   \n",
              "28518   0.129601  -0.855883   0.201302   -0.727748  ...     0.465296   \n",
              "28519   0.601866   0.921103  -1.020922    1.548995  ...     0.079121   \n",
              "\n",
              "       feature_248  feature_249  feature_250  feature_251  feature_252  \\\n",
              "0         1.101137    -0.786061     0.622750    -0.503841    -0.862208   \n",
              "1        -0.688550    -1.640606    -0.053767    -0.486404    -0.493145   \n",
              "2         0.303437    -2.323521    -0.182392    -0.006368     0.086269   \n",
              "3        -0.102070    -2.596694    -0.616500     0.544197     0.307588   \n",
              "4        -0.117040    -1.419770     0.362046    -0.435119    -0.786176   \n",
              "...            ...          ...          ...          ...          ...   \n",
              "28515    -0.158732    -0.525769     1.257927     0.567362    -0.776576   \n",
              "28516    -0.432984    -0.031154     0.887144    -0.127631     0.039676   \n",
              "28517    -0.180739    -0.387017    -0.955283     0.850339    -1.401814   \n",
              "28518     0.307306     0.663333     0.233262     0.540602    -0.434947   \n",
              "28519    -0.087894    -1.330237    -0.403272     0.973497    -0.812996   \n",
              "\n",
              "       feature_253  feature_254  feature_255  feature_256  \n",
              "0        -1.063657    -0.033389    -0.726253     0.785181  \n",
              "1        -1.293456    -0.320623     0.746471    -0.660619  \n",
              "2         0.762691     0.577715    -0.946525    -0.585987  \n",
              "3        -0.577020     0.401594    -1.154003     0.207497  \n",
              "4         0.068403    -0.787532     1.939043     0.183946  \n",
              "...            ...          ...          ...          ...  \n",
              "28515    -0.718924     0.924023     0.570760     0.442692  \n",
              "28516    -0.151647    -0.303670     0.903381    -0.282937  \n",
              "28517     0.774752     1.397541    -0.214777    -0.206945  \n",
              "28518     0.085522    -0.173189    -1.037877    -0.075089  \n",
              "28519     1.066722     1.259609    -0.024581    -1.249044  \n",
              "\n",
              "[28520 rows x 256 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ce8ed58-90db-4120-8ad4-711420bd280a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_247</th>\n",
              "      <th>feature_248</th>\n",
              "      <th>feature_249</th>\n",
              "      <th>feature_250</th>\n",
              "      <th>feature_251</th>\n",
              "      <th>feature_252</th>\n",
              "      <th>feature_253</th>\n",
              "      <th>feature_254</th>\n",
              "      <th>feature_255</th>\n",
              "      <th>feature_256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.309586</td>\n",
              "      <td>0.235701</td>\n",
              "      <td>0.943739</td>\n",
              "      <td>1.110687</td>\n",
              "      <td>0.493583</td>\n",
              "      <td>-0.232368</td>\n",
              "      <td>-0.624554</td>\n",
              "      <td>-0.504571</td>\n",
              "      <td>0.132999</td>\n",
              "      <td>0.095217</td>\n",
              "      <td>...</td>\n",
              "      <td>1.583006</td>\n",
              "      <td>1.101137</td>\n",
              "      <td>-0.786061</td>\n",
              "      <td>0.622750</td>\n",
              "      <td>-0.503841</td>\n",
              "      <td>-0.862208</td>\n",
              "      <td>-1.063657</td>\n",
              "      <td>-0.033389</td>\n",
              "      <td>-0.726253</td>\n",
              "      <td>0.785181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.144159</td>\n",
              "      <td>-0.295674</td>\n",
              "      <td>0.837377</td>\n",
              "      <td>2.514509</td>\n",
              "      <td>-0.718433</td>\n",
              "      <td>1.537233</td>\n",
              "      <td>0.286751</td>\n",
              "      <td>-0.431414</td>\n",
              "      <td>1.105227</td>\n",
              "      <td>-0.783768</td>\n",
              "      <td>...</td>\n",
              "      <td>1.036040</td>\n",
              "      <td>-0.688550</td>\n",
              "      <td>-1.640606</td>\n",
              "      <td>-0.053767</td>\n",
              "      <td>-0.486404</td>\n",
              "      <td>-0.493145</td>\n",
              "      <td>-1.293456</td>\n",
              "      <td>-0.320623</td>\n",
              "      <td>0.746471</td>\n",
              "      <td>-0.660619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.292525</td>\n",
              "      <td>0.186803</td>\n",
              "      <td>-0.330437</td>\n",
              "      <td>2.726045</td>\n",
              "      <td>-0.915203</td>\n",
              "      <td>1.013608</td>\n",
              "      <td>1.247330</td>\n",
              "      <td>-1.564947</td>\n",
              "      <td>0.951931</td>\n",
              "      <td>-1.012765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.297848</td>\n",
              "      <td>0.303437</td>\n",
              "      <td>-2.323521</td>\n",
              "      <td>-0.182392</td>\n",
              "      <td>-0.006368</td>\n",
              "      <td>0.086269</td>\n",
              "      <td>0.762691</td>\n",
              "      <td>0.577715</td>\n",
              "      <td>-0.946525</td>\n",
              "      <td>-0.585987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.669594</td>\n",
              "      <td>-1.191524</td>\n",
              "      <td>-0.251777</td>\n",
              "      <td>0.560848</td>\n",
              "      <td>0.193810</td>\n",
              "      <td>0.728978</td>\n",
              "      <td>0.931314</td>\n",
              "      <td>0.170499</td>\n",
              "      <td>1.527067</td>\n",
              "      <td>0.288711</td>\n",
              "      <td>...</td>\n",
              "      <td>0.829376</td>\n",
              "      <td>-0.102070</td>\n",
              "      <td>-2.596694</td>\n",
              "      <td>-0.616500</td>\n",
              "      <td>0.544197</td>\n",
              "      <td>0.307588</td>\n",
              "      <td>-0.577020</td>\n",
              "      <td>0.401594</td>\n",
              "      <td>-1.154003</td>\n",
              "      <td>0.207497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.345805</td>\n",
              "      <td>0.084043</td>\n",
              "      <td>0.418116</td>\n",
              "      <td>2.155265</td>\n",
              "      <td>-0.227710</td>\n",
              "      <td>1.064978</td>\n",
              "      <td>-0.248008</td>\n",
              "      <td>0.090402</td>\n",
              "      <td>0.538791</td>\n",
              "      <td>-1.573073</td>\n",
              "      <td>...</td>\n",
              "      <td>1.058010</td>\n",
              "      <td>-0.117040</td>\n",
              "      <td>-1.419770</td>\n",
              "      <td>0.362046</td>\n",
              "      <td>-0.435119</td>\n",
              "      <td>-0.786176</td>\n",
              "      <td>0.068403</td>\n",
              "      <td>-0.787532</td>\n",
              "      <td>1.939043</td>\n",
              "      <td>0.183946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28515</th>\n",
              "      <td>0.043336</td>\n",
              "      <td>1.192542</td>\n",
              "      <td>-0.149975</td>\n",
              "      <td>0.011312</td>\n",
              "      <td>2.636595</td>\n",
              "      <td>-0.068369</td>\n",
              "      <td>-0.978061</td>\n",
              "      <td>0.177880</td>\n",
              "      <td>1.175240</td>\n",
              "      <td>0.563477</td>\n",
              "      <td>...</td>\n",
              "      <td>0.670030</td>\n",
              "      <td>-0.158732</td>\n",
              "      <td>-0.525769</td>\n",
              "      <td>1.257927</td>\n",
              "      <td>0.567362</td>\n",
              "      <td>-0.776576</td>\n",
              "      <td>-0.718924</td>\n",
              "      <td>0.924023</td>\n",
              "      <td>0.570760</td>\n",
              "      <td>0.442692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28516</th>\n",
              "      <td>1.215430</td>\n",
              "      <td>-0.535137</td>\n",
              "      <td>0.051517</td>\n",
              "      <td>-0.021644</td>\n",
              "      <td>0.280856</td>\n",
              "      <td>-0.269055</td>\n",
              "      <td>0.761116</td>\n",
              "      <td>-1.611506</td>\n",
              "      <td>-0.137716</td>\n",
              "      <td>0.093801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.680854</td>\n",
              "      <td>-0.432984</td>\n",
              "      <td>-0.031154</td>\n",
              "      <td>0.887144</td>\n",
              "      <td>-0.127631</td>\n",
              "      <td>0.039676</td>\n",
              "      <td>-0.151647</td>\n",
              "      <td>-0.303670</td>\n",
              "      <td>0.903381</td>\n",
              "      <td>-0.282937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28517</th>\n",
              "      <td>0.997528</td>\n",
              "      <td>-0.016963</td>\n",
              "      <td>0.116092</td>\n",
              "      <td>0.297648</td>\n",
              "      <td>1.067387</td>\n",
              "      <td>0.208798</td>\n",
              "      <td>0.236824</td>\n",
              "      <td>-0.038200</td>\n",
              "      <td>0.211088</td>\n",
              "      <td>0.628452</td>\n",
              "      <td>...</td>\n",
              "      <td>0.334185</td>\n",
              "      <td>-0.180739</td>\n",
              "      <td>-0.387017</td>\n",
              "      <td>-0.955283</td>\n",
              "      <td>0.850339</td>\n",
              "      <td>-1.401814</td>\n",
              "      <td>0.774752</td>\n",
              "      <td>1.397541</td>\n",
              "      <td>-0.214777</td>\n",
              "      <td>-0.206945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28518</th>\n",
              "      <td>-0.605893</td>\n",
              "      <td>-0.008649</td>\n",
              "      <td>0.009349</td>\n",
              "      <td>-0.613440</td>\n",
              "      <td>0.888404</td>\n",
              "      <td>-0.589037</td>\n",
              "      <td>0.129601</td>\n",
              "      <td>-0.855883</td>\n",
              "      <td>0.201302</td>\n",
              "      <td>-0.727748</td>\n",
              "      <td>...</td>\n",
              "      <td>0.465296</td>\n",
              "      <td>0.307306</td>\n",
              "      <td>0.663333</td>\n",
              "      <td>0.233262</td>\n",
              "      <td>0.540602</td>\n",
              "      <td>-0.434947</td>\n",
              "      <td>0.085522</td>\n",
              "      <td>-0.173189</td>\n",
              "      <td>-1.037877</td>\n",
              "      <td>-0.075089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28519</th>\n",
              "      <td>0.763188</td>\n",
              "      <td>-0.207126</td>\n",
              "      <td>0.459697</td>\n",
              "      <td>-0.435380</td>\n",
              "      <td>0.961052</td>\n",
              "      <td>-0.455518</td>\n",
              "      <td>0.601866</td>\n",
              "      <td>0.921103</td>\n",
              "      <td>-1.020922</td>\n",
              "      <td>1.548995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.079121</td>\n",
              "      <td>-0.087894</td>\n",
              "      <td>-1.330237</td>\n",
              "      <td>-0.403272</td>\n",
              "      <td>0.973497</td>\n",
              "      <td>-0.812996</td>\n",
              "      <td>1.066722</td>\n",
              "      <td>1.259609</td>\n",
              "      <td>-0.024581</td>\n",
              "      <td>-1.249044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28520 rows × 256 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ce8ed58-90db-4120-8ad4-711420bd280a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ce8ed58-90db-4120-8ad4-711420bd280a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ce8ed58-90db-4120-8ad4-711420bd280a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-53aad199-8ebf-4136-b307-98e91365262d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-53aad199-8ebf-4136-b307-98e91365262d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-53aad199-8ebf-4136-b307-98e91365262d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(x_train[L4], y_train[L4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ZQu0av-ZcTnP",
        "outputId": "d2380442-7541-460c-f57b-d59fc70fac34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-27 {color: black;background-color: white;}#sk-container-id-27 pre{padding: 0;}#sk-container-id-27 div.sk-toggleable {background-color: white;}#sk-container-id-27 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-27 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-27 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-27 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-27 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-27 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-27 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-27 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-27 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-27 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-27 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-27 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-27 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-27 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-27 div.sk-item {position: relative;z-index: 1;}#sk-container-id-27 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-27 div.sk-item::before, #sk-container-id-27 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-27 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-27 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-27 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-27 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-27 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-27 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-27 div.sk-label-container {text-align: center;}#sk-container-id-27 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-27 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-27\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" checked><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "y_pred = knn.predict(x_valid[L4]) # Predicting the validation data set"
      ],
      "metadata": {
        "id": "4qLIktTmcxje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy of the validation data set\n",
        "print(metrics.confusion_matrix(y_valid[L4], y_pred))\n",
        "print(metrics.accuracy_score(y_valid[L4], y_pred))\n",
        "print(metrics.precision_score(y_valid[L4], y_pred, average='weighted'))\n",
        "print(metrics.recall_score(y_valid[L4], y_pred, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY5Xli6qc4vW",
        "outputId": "f70ac9da-d7a8-44da-cebb-8710cdffedf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 21   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0  11   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0  27   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   8   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  15   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  10   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 532   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1  31   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1   0  18   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  17   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  10   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11   0   0]\n",
            " [  0   0   0   0   0   0   1   1   0   0   0   0  24   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  10]]\n",
            "0.9933333333333333\n",
            "0.9933731343283582\n",
            "0.9933333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting the label_4 of the test data set\n",
        "y_pred_test = knn.predict(x_test[L4])"
      ],
      "metadata": {
        "id": "Xb-VpxfadBr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ubb0fHSCdVfL",
        "outputId": "776d013d-f39d-4657-b852-83b525a334e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6, 13, 13, 13, 13, 13, 13, 13,  2,  4,  4,  4,  4,  4,  4,  4,  4,\n",
              "        4,  4,  4,  4,  6,  4,  4,  4,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  2,  2,  2,  2,  2,  2,  2,\n",
              "        2,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,\n",
              "        7,  7,  7,  7,  7,  7,  7, 12,  7,  7,  7,  7,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
              "       12, 12, 12,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  2,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6, 12,\n",
              "       12, 12, 12, 12, 12, 12,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
              "        9,  2,  2,  2,  2,  2,  2,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6, 11, 11, 11, 11, 11, 11, 11,\n",
              "       11, 11,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,\n",
              "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2, 10, 10, 10, 10, 10,\n",
              "       10, 10, 10, 10, 10,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  2,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6])"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With Feature Engineering"
      ],
      "metadata": {
        "id": "tynVuL39dXpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# With  selectKBest method\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "selector =  SelectKBest(f_classif, k=40) #  with only using 40 features\n",
        "x_new_train = selector.fit_transform(x_train[L4], y_train[L4])\n",
        "x_new_valid = selector.transform(x_valid[L4])\n",
        "x_new_test = selector.transform(x_test[L4])\n",
        "print('shape training', x_new_train.shape)\n",
        "print('shape validation', x_new_valid.shape)\n",
        "print('shape test', x_new_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOiqIa0Zda0f",
        "outputId": "b47fd3e5-f13c-47ba-b569-6d7f2e82621e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape training (28520, 40)\n",
            "shape validation (750, 40)\n",
            "shape test (750, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(x_new_train, y_train[L4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "vzGtuGaAds-I",
        "outputId": "080d1702-ea7a-4bbb-c7af-820246f7723d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-28 {color: black;background-color: white;}#sk-container-id-28 pre{padding: 0;}#sk-container-id-28 div.sk-toggleable {background-color: white;}#sk-container-id-28 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-28 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-28 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-28 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-28 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-28 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-28 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-28 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-28 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-28 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-28 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-28 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-28 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-28 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-28 div.sk-item {position: relative;z-index: 1;}#sk-container-id-28 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-28 div.sk-item::before, #sk-container-id-28 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-28 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-28 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-28 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-28 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-28 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-28 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-28 div.sk-label-container {text-align: center;}#sk-container-id-28 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-28 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-28\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" checked><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = knn.predict(selector.transform(x_valid[L4]))\n",
        "print(metrics.confusion_matrix(y_valid[L4], y_pred))\n",
        "print(metrics.accuracy_score(y_valid[L4], y_pred))\n",
        "print(metrics.precision_score(y_valid[L4], y_pred, average='weighted'))\n",
        "print(metrics.recall_score(y_valid[L4], y_pred, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHjeCO8ydveA",
        "outputId": "c948f622-777f-4d8f-a4f2-2e04f63a0654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 19   0   0   0   0   0   2   0   0   0   0   0   0   0]\n",
            " [  0  10   0   0   0   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0  26   0   0   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   7   0   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  15   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  10   1   0   0   0   0   0   0   0]\n",
            " [  2   0   1   0   0   0 529   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1  31   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   2   0  17   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  17   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  10   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11   0   0]\n",
            " [  0   0   0   0   0   0   4   0   0   0   0   0  22   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  10]]\n",
            "0.9786666666666667\n",
            "0.9789864698646987\n",
            "0.9786666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding PCA to the selectKBest results\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=0.95, svd_solver='full')\n",
        "pca.fit(x_new_train)\n",
        "x_train_trf = pd.DataFrame(pca.transform(x_new_train)) # transforming data to fit into pca\n",
        "x_valid_trf = pd.DataFrame(pca.transform(x_new_valid))\n",
        "x_test_trf = pd.DataFrame(pca.transform(x_new_test))\n",
        "print('Shape after PCA x_train : ', x_train_trf.shape)\n",
        "print('Shape after PCA x_valid : ', x_valid_trf.shape)\n",
        "print('Shape after PCA x_test : ', x_valid_trf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pettGlbUgHoG",
        "outputId": "169507e3-05a0-4496-c6df-ee33961ee458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after PCA x_train :  (28520, 28)\n",
            "Shape after PCA x_valid :  (750, 28)\n",
            "Shape after PCA x_test :  (750, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(x_train_trf, y_train[L4])\n",
        "\n",
        "y_pred = knn.predict(x_valid_trf)\n",
        "print(metrics.confusion_matrix(y_valid[L4], y_pred))\n",
        "print(metrics.accuracy_score(y_valid[L4], y_pred))\n",
        "print(metrics.precision_score(y_valid[L4], y_pred, average='weighted'))\n",
        "print(metrics.recall_score(y_valid[L4], y_pred, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpNKU1QtgOrn",
        "outputId": "a2cdd758-0cfe-44c5-fa44-cbdf7ac8aacc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 18   0   1   0   0   0   2   0   0   0   0   0   0   0]\n",
            " [  0  11   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0  26   0   0   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   7   0   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  15   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  10   1   0   0   0   0   0   0   0]\n",
            " [  2   0   1   0   0   0 527   0   0   1   0   0   1   0]\n",
            " [  0   0   0   0   0   0   2  30   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   4   1  14   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  17   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  10   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11   0   0]\n",
            " [  0   0   0   0   0   0   3   0   0   0   0   0  23   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  10]]\n",
            "0.972\n",
            "0.9721923930165417\n",
            "0.972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting the test data\n",
        "y_pred_test_fe = knn.predict(x_test_trf)\n",
        "y_pred_test_fe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHVgV3MxgvKw",
        "outputId": "1df32cd5-25fd-4b70-fc64-cc49e9d930fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6, 13, 13, 13, 13, 13, 13, 13,  2,  0,  6,  4,  4,  4,  4,  4,  4,\n",
              "        4,  4,  1,  4,  4,  4,  4,  4,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  2,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  2,  2,  2,  2,  2,  6,  2,\n",
              "        2,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  0,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,\n",
              "        7,  7,  7,  7,  6,  7,  7,  6,  7,  7,  7,  7,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  0,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  3,  3,  6,  3,  3,  3,  3,  3,  3,  6,  3,  3,  3,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  0,  0,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
              "       12, 12, 12,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6, 12,\n",
              "       12, 12, 12, 12, 12,  8,  9,  9,  9,  9,  9,  9,  9,  6,  9,  9,  9,\n",
              "        9,  2,  2,  2,  2,  2,  2,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  2,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  8,  8,  8,  8,  8,  0,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6, 11, 11, 11, 11, 11, 11, 11,\n",
              "       11, 11,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  6,  7,\n",
              "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  0,  0,  0,  6,  0,  0,  0,\n",
              "        0,  0,  2,  2,  2,  2,  2,  3,  2,  2,  2,  2, 10, 10, 10, 10, 10,\n",
              "       10, 10,  6, 10, 10,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  2,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  2,\n",
              "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6])"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df = pd.DataFrame({\n",
        "    'Predicted labels before feature engineering': y_pred_test,\n",
        "    'Predicted labels after feature engineering': y_pred_test_fe,\n",
        "    'No. of new features': x_test_trf.shape[1]\n",
        "})\n",
        "\n",
        "\n",
        "for i in range(x_test_trf.shape[1]):\n",
        "    output_df[f'New feature {i+1}'] = x_test_trf.iloc[:, i]\n",
        "output_df\n",
        "output_df.to_csv('/content/drive/MyDrive/Colab Notebooks/190294K_label_4.csv',index=False)"
      ],
      "metadata": {
        "id": "f7h7HRQfg7NW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}